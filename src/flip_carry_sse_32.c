/**
 * @file flip_carry_sse_32.c
 *
 * This module deals with flipping discs.
 *
 * A function is provided for each square of the board. These functions are
 * gathered into an array of functions, so that a fast access to each function
 * is allowed. The generic form of the function take as input the player and
 * the opponent bitboards and return the flipped squares into a bitboard.
 *
 * Given the following notation:
 *  - x = square where we play,
 *  - P = player's disc pattern,
 *  - O = opponent's disc pattern,
 * the basic principle is to read into an array the result of a move. Doing
 * this is easier for a single line ; so we can use arrays of the form:
 *  - ARRAY[x][8-bits disc pattern].
 * The problem is thus to convert any line of a 64-bits disc pattern into an
 * 8-bits disc pattern. A fast way to do this is to select the right line,
 * with a bit-mask, to gather the masked-bits into a continuous set by a simple
 * multiplication and to right-shift the result to scale it into a number
 * between 0 and 255.
 * Once we get our 8-bits disc patterns,a first array (OUTFLANK) is used to
 * get the player's discs that surround the opponent discs:
 *  - outflank = OUTFLANK[x][O] & P
 * (Only inner 6-bits of the P are in interest here.)
 * The result is then used as an index to access a second array giving the
 * flipped discs according to the surrounding player's discs:
 *  - flipped = FLIPPED[x][outflank].
 * (Flipped discs fall into inner 6-bits.)
 * Finally, a precomputed array transform the inner 6-bits disc pattern back into a
 * 64-bits disc pattern, and the flipped squares for each line are gathered and
 * returned to generate moves.
 *
 * If the OUTFLANK search is in LSB to MSB direction, carry propagation 
 * can be used to determine contiguous discs.
 *
 * @date 1998 - 2018
 * @author Richard Delorme
 * @author Toshihiko Okuhara
 * @version 4.4
 */

#if defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
#include <string.h>	// memcpy
#endif

#ifdef __TURBOC__
// bcc32 -c -pr -O1 flip_carry_sse_32.c
#pragma warn -ngu
#define	UINT64	unsigned __int64
#else
#include "bit.h"
#define	UINT64	unsigned long long
#endif

#ifdef USE_GAS_MMX
#define	STATIC	__attribute__((used))
#ifdef __unix__
#define	_
#else
#define	_	"_"
#endif
#else
#define	STATIC	static
#endif

#define	ULL(H,L)	(((UINT64) (H) << 32) | (L))

/** outflank array (indexed with inner 6 bits) */
/* static const unsigned char OUTFLANK_0[64] = {
	0x00, 0x04, 0x00, 0x08, 0x00, 0x04, 0x00, 0x10, 0x00, 0x04, 0x00, 0x08, 0x00, 0x04, 0x00, 0x20,
	0x00, 0x04, 0x00, 0x08, 0x00, 0x04, 0x00, 0x10, 0x00, 0x04, 0x00, 0x08, 0x00, 0x04, 0x00, 0x40,
	0x00, 0x04, 0x00, 0x08, 0x00, 0x04, 0x00, 0x10, 0x00, 0x04, 0x00, 0x08, 0x00, 0x04, 0x00, 0x20,
	0x00, 0x04, 0x00, 0x08, 0x00, 0x04, 0x00, 0x10, 0x00, 0x04, 0x00, 0x08, 0x00, 0x04, 0x00, 0x80
}; */

/* static const unsigned char OUTFLANK_1[64] = {
	0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x20, 0x00,
	0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x40, 0x00,
	0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x20, 0x00,
	0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x80, 0x00
}; */

STATIC const unsigned char OUTFLANK_2[64] = {
	0x00, 0x01, 0x00, 0x00, 0x10, 0x11, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x20, 0x21, 0x00, 0x00,
	0x00, 0x01, 0x00, 0x00, 0x10, 0x11, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x40, 0x41, 0x00, 0x00,
	0x00, 0x01, 0x00, 0x00, 0x10, 0x11, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x20, 0x21, 0x00, 0x00,
	0x00, 0x01, 0x00, 0x00, 0x10, 0x11, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x80, 0x81, 0x00, 0x00
};

STATIC const unsigned char OUTFLANK_3[64] = {
	0x00, 0x00, 0x02, 0x01, 0x00, 0x00, 0x00, 0x00, 0x20, 0x20, 0x22, 0x21, 0x00, 0x00, 0x00, 0x00,
	0x00, 0x00, 0x02, 0x01, 0x00, 0x00, 0x00, 0x00, 0x40, 0x40, 0x42, 0x41, 0x00, 0x00, 0x00, 0x00,
	0x00, 0x00, 0x02, 0x01, 0x00, 0x00, 0x00, 0x00, 0x20, 0x20, 0x22, 0x21, 0x00, 0x00, 0x00, 0x00,
	0x00, 0x00, 0x02, 0x01, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x82, 0x81, 0x00, 0x00, 0x00, 0x00
};

STATIC const unsigned char OUTFLANK_4[64] = {
	0x00, 0x00, 0x00, 0x00, 0x04, 0x04, 0x02, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x40, 0x40, 0x40, 0x40, 0x44, 0x44, 0x42, 0x41, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x00, 0x00, 0x00, 0x00, 0x04, 0x04, 0x02, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x84, 0x84, 0x82, 0x81, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
};

STATIC const unsigned char OUTFLANK_5[64] = {
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0x08, 0x08, 0x08, 0x04, 0x04, 0x02, 0x01,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x88, 0x88, 0x88, 0x88, 0x84, 0x84, 0x82, 0x81,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
};

/* static const unsigned char OUTFLANK_6[64] = {
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x08, 0x08, 0x08, 0x08, 0x04, 0x04, 0x02, 0x01,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
}; */

STATIC const unsigned char OUTFLANK_7[64] = {
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,
	0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x10, 0x08, 0x08, 0x08, 0x08, 0x04, 0x04, 0x02, 0x01
};


/** flip array (indexed with outflank, returns inner 6 bits) */
STATIC const UINT64 FLIPPED_2_H[130] = {
	0x0000000000000000, 0x0202020202020202, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0808080808080808, 0x0a0a0a0a0a0a0a0a, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x1818181818181818, 0x1a1a1a1a1a1a1a1a, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x3838383838383838, 0x3a3a3a3a3a3a3a3a, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x7878787878787878, 0x7a7a7a7a7a7a7a7a
};

STATIC const UINT64 FLIPPED_3_H[131] = {
	0x0000000000000000, 0x0606060606060606, 0x0404040404040404, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x1010101010101010, 0x1616161616161616, 0x1414141414141414, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x3030303030303030, 0x3636363636363636, 0x3434343434343434, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x7070707070707070, 0x7676767676767676, 0x7474747474747474
};

STATIC const UINT64 FLIPPED_4_H[133] = {
	0x0000000000000000, 0x0e0e0e0e0e0e0e0e, 0x0c0c0c0c0c0c0c0c, 0x0000000000000000, 0x0808080808080808, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x2020202020202020, 0x2e2e2e2e2e2e2e2e, 0x2c2c2c2c2c2c2c2c, 0x0000000000000000, 0x2828282828282828, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x6060606060606060, 0x6e6e6e6e6e6e6e6e, 0x6c6c6c6c6c6c6c6c, 0x0000000000000000, 0x6868686868686868
};

STATIC const UINT64 FLIPPED_5_H[137] = {
	0x0000000000000000, 0x1e1e1e1e1e1e1e1e, 0x1c1c1c1c1c1c1c1c, 0x0000000000000000, 0x1818181818181818, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x1010101010101010, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x4040404040404040, 0x5e5e5e5e5e5e5e5e, 0x5c5c5c5c5c5c5c5c, 0x0000000000000000, 0x5858585858585858, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x5050505050505050
};

STATIC const UINT64 FLIPPED_3_V[131] = {
	0x0000000000000000, 0x0000000000ffff00, 0x0000000000ff0000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x000000ff00000000, 0x000000ff00ffff00, 0x000000ff00ff0000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000ffff00000000, 0x0000ffff00ffff00, 0x0000ffff00ff0000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x00ffffff00000000, 0x00ffffff00ffff00, 0x00ffffff00ff0000
};

STATIC const UINT64 FLIPPED_4_V[133] = {
	0x0000000000000000, 0x00000000ffffff00, 0x00000000ffff0000, 0x0000000000000000, 0x00000000ff000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000ff0000000000, 0x0000ff00ffffff00, 0x0000ff00ffff0000, 0x0000000000000000, 0x0000ff00ff000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x00ffff0000000000, 0x00ffff00ffffff00, 0x00ffff00ffff0000, 0x0000000000000000, 0x00ffff00ff000000
};

STATIC const UINT64 FLIPPED_5_V[137] = {
	0x0000000000000000, 0x000000ffffffff00, 0x000000ffffff0000, 0x0000000000000000, 0x000000ffff000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x000000ff00000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x00ff000000000000, 0x00ff00ffffffff00, 0x00ff00ffffff0000, 0x0000000000000000, 0x00ff00ffff000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x00ff00ff00000000
};


/*
 * Set all bits below the sole outflank bit if outfrank != 0
 */
#if (_MSC_VER >= 1800) && (defined(_M_IX86) || defined (_M_X64))
static inline unsigned long long OutflankToFlipmask(unsigned long long outflank) {
	unsigned int flipmaskL, flipmaskH, outflankH = outflank >> 32;
	unsigned char cy;
	cy = _subborrow_u32(0, outflank, 1, &flipmaskL);
	cy = _subborrow_u32(cy, outflankH, 0, &flipmaskH);
	cy = _addcarry_u32(cy, flipmaskL, 0, &flipmaskL);
	_addcarry_u32(cy, flipmaskH, 0, &flipmaskH);
	return ULL(flipmaskH, flipmaskL);
}
#else
	#define OutflankToFlipmask(x)	((x) - (unsigned int) ((x) != 0))
#endif

#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)

#define minusone	_mm_set1_epi32(-1)
static const V2DI	k1e52 = {{ (1023ULL + 52) << 52, (1023ULL + 52) << 52 }};
static const V2DI	expmask = {{ 0xfff0000000000000, 0xfff0000000000000 }};
static const V2DI	minustwo   = {{ 0xfffefffefffefffe, 0xfffefffefffefffe }};
static const V2DI	minusfour  = {{ 0xfffcfffcfffcfffc, 0xfffcfffcfffcfffc }};
static const V2DI	minuseight = {{ 0xfff8fff8fff8fff8, 0xfff8fff8fff8fff8 }};
static const V2DI	minus0400  = {{ 0xfc00fc00fc00fc00, 0xfc00fc00fc00fc00 }};
static const V2DI	minus0800  = {{ 0xf800f800f800f800, 0xf800f800f800f800 }};
static const V2DI	k02000100  = {{ 0x0100000000000100, 0x0200000000000200 }};


STATIC const UINT64 OUTFLANK_7_V[64] = {
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000,
	0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000, 0x0000ff0000000000,
	0x000000ff00000000, 0x000000ff00000000, 0x000000ff00000000, 0x000000ff00000000, 0x000000ff00000000, 0x000000ff00000000, 0x000000ff00000000, 0x000000ff00000000,
	0x00000000ff000000, 0x00000000ff000000, 0x00000000ff000000, 0x00000000ff000000, 0x0000000000ff0000, 0x0000000000ff0000, 0x000000000000ff00, 0x00000000000000ff
};


STATIC const UINT64 FLIPPED_7_V[33] = {
	0x0000000000000000, 0x00ffffffffffff00, 0x00ffffffffff0000, 0x0000000000000000, 0x00ffffffff000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x00ffffff00000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x00ffff0000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000,
	0x00ff000000000000
};

#if defined(hasSSE2) || defined(USE_MSVC_X86)

#define	SWAP64	0x4e	// for _mm_shuffle_epi32
#define	SWAP32	0xb1
#define	DUPLO	0x44
#define	DUPHI	0xee


/*
 * Extract most significant bit set from 2 x i32
 */
static inline __m128i MS1B_epi32(__m128i x) {
	return _mm_cvtpd_epi32(_mm_and_pd(_mm_cvtepi32_pd(x), expmask.d2));	// clear mantissa = non msb bits
}

/*
 * Extract most significant bit set
 * valid only for x < 0x000fffffffffffffULL
 *
 * https://software.intel.com/en-us/forums/intel-isa-extensions/topic/301988
 */
static inline __m128i MS1B_epi52(__m128i x) {
	__m128d f;
	f = _mm_or_pd(_mm_castsi128_pd(x), k1e52.d2);	// construct double x + 2^52
	f = _mm_sub_pd(f, k1e52.d2);	// extract 2^52 from double -- mantissa will be automatically normalized
	f = _mm_and_pd(f, expmask.d2);	// clear mantissa = non msb bits
	f = _mm_add_pd(f, k1e52.d2);	// add 2^52 to push back the msb
	// f = _mm_xor_pd(f, k1e52.d2);	// remove exponent	// cleared in caller
	return _mm_castpd_si128(f);
}
/**
 * Make inverted flip mask if opponent's disc are surrounded by player's.
 *
 * 0xffffffffffffffff (-1) if outflank is 0
 * 0x0000000000000000 ( 0) if a 1 is in 64 bit
 */
static inline __m128i flipmask (__m128i outflank) {
	return _mm_cmpeq_epi32(_mm_shuffle_epi32(outflank, SWAP32), outflank);
}

/**
 * Load 2 unsigned long longs into xmm.
 */
static inline __m128i load64x2 (const UINT64 *x0, const UINT64 *x1) {
	return _mm_castps_si128(_mm_loadh_pi(_mm_castsi128_ps(_mm_loadl_epi64((__m128i *) x0)), (__m64 *) x1));
}

/**
 * _mm_set1_epi64x equivalent to utilize store to load forwarding
 *
 * AMD 47414 pp.96
 */
static inline __m128i set1_by_movd (unsigned int L, unsigned int H) {
	__m128i	Y;
	Y = _mm_unpacklo_epi32(_mm_cvtsi32_si128(L), _mm_cvtsi32_si128(H));
	return _mm_unpacklo_epi64(Y, Y);
}

#define FLIP_CARRY_2_VEC(flip_l)	__m128i	outflank_vd;\
	outflank_vd = _mm_andnot_si128(set1_by_movd(OL, OH), mask.v2);\
	outflank_vd = _mm_and_si128(_mm_and_si128(outflank_vd, _mm_sub_epi64(_mm_setzero_si128(), outflank_vd)), set1_by_movd(PL, PH));\
	outflank_vd = _mm_and_si128(mask.v2, _mm_sub_epi64(outflank_vd, _mm_sub_epi64(flipmask(outflank_vd), minusone)));\
	flipped = _mm_cvtsi128_si64(_mm_or_si128(outflank_vd, _mm_shuffle_epi32(outflank_vd, SWAP64))) | (flip_l)

#define FLIP_CARRY_AB12(next)	__m128i outflank_vd, outflank_h, flipped_v2, PP, OO;\
	const __m128i next_h = _mm_loadl_epi64((__m128i *) &X_TO_BIT[next]);\
	OO = set1_by_movd(OL, OH);\
	PP = set1_by_movd(PL, PH);\
	outflank_vd = _mm_andnot_si128(OO, mask.v2);\
	outflank_vd = _mm_and_si128(_mm_and_si128(outflank_vd, _mm_sub_epi64(_mm_setzero_si128(), outflank_vd)), PP);\
	flipped_v2 = _mm_and_si128(mask.v2, _mm_sub_epi64(outflank_vd, _mm_sub_epi64(flipmask(outflank_vd), minusone)));\
	outflank_h = _mm_and_si128(_mm_add_epi8(OO, next_h), PP);\
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_subs_epu8(outflank_h, next_h));\
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)))

#define	FLIP_CARRY_3_VEC(flip_l)	__m128i	outflank_vd, outflank_d_, PP, OO, mask2_;\
	OO = set1_by_movd(OL, OH);\
	PP = set1_by_movd(PL, PH);\
	mask2_ = _mm_loadl_epi64((__m128i *) &mask2);\
	outflank_vd = _mm_and_si128(_mm_andnot_si128(mask01.v2, _mm_sub_epi64(_mm_or_si128(OO, mask01.v2), minusone)), PP);\
	outflank_d_ = _mm_and_si128(_mm_andnot_si128(mask2_, _mm_sub_epi64(_mm_or_si128(OO, mask2_), minusone)), PP);\
	outflank_vd = _mm_andnot_si128(mask01.v2, _mm_sub_epi64(outflank_vd, _mm_sub_epi64(flipmask(outflank_vd), minusone)));\
	outflank_d_ = _mm_andnot_si128(mask2_, _mm_sub_epi64(outflank_d_, _mm_sub_epi64(flipmask(outflank_d_), minusone)));\
	outflank_vd = _mm_or_si128(outflank_vd, _mm_or_si128(_mm_shuffle_epi32(outflank_vd, SWAP64), outflank_d_));\
	flipped = _mm_cvtsi128_si64(outflank_vd) | (flip_l)

#define FLIP_CARRY_GH12	__m128i outflank_vd, outflank_h, flipped_v2, PP, OO;\
	OO = set1_by_movd(OL, OH);\
	PP = set1_by_movd(PL, PH);\
	outflank_vd = _mm_andnot_si128(OO, mask1.v2);\
	outflank_vd = _mm_and_si128(_mm_and_si128(outflank_vd, _mm_sub_epi64(_mm_setzero_si128(), outflank_vd)), PP);\
	flipped_v2 = _mm_and_si128(mask1.v2, _mm_sub_epi64(outflank_vd, _mm_sub_epi64(flipmask(outflank_vd), minusone)));\
	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(OO, mask2.v2)), PP);\
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_and_si128(_mm_mullo_epi16(outflank_h, minustwo.v2), mask2.v2));\
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)))

#define FLIP_MS1B_2_VEC	__m128i PP = set1_by_movd(PL, PH);\
	__m128i OO = set1_by_movd(OL, OH);\
	__m128i outflank_vd = _mm_and_si128(MS1B_epi52(_mm_andnot_si128(OO, mask1.v2)), PP);\
	__m128i flipped_v2 = _mm_and_si128(_mm_sub_epi64(_mm_setzero_si128(), _mm_add_epi64(outflank_vd, outflank_vd)), mask1.v2);\
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)))

#define FLIP_MS1B_AB78(next)	__m128i PP = set1_by_movd(PL, PH);\
	__m128i OO = set1_by_movd(OL, OH);\
	__m128i outflank_vd = _mm_and_si128(MS1B_epi52(_mm_andnot_si128(OO, mask1.v2)), PP);\
	__m128i flipped_v2 = _mm_and_si128(_mm_sub_epi64(_mm_setzero_si128(), _mm_add_epi64(outflank_vd, outflank_vd)), mask1.v2);\
	__m128i next_h = _mm_loadl_epi64((__m128i *) &X_TO_BIT[next]);\
	__m128i outflank_h = _mm_and_si128(_mm_add_epi8(OO, next_h), PP);\
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_subs_epu8(outflank_h, next_h));\
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)))

#else

#define FLIP_CARRY_2_VEC(flip_l)	__asm__ (\
		"movd	%1, %%xmm0\n\t"		"movd	%3, %%xmm1\n\t"\
		"movd	%2, %%xmm2\n\t"		"movd	%4, %%xmm3\n\t"\
		"punpckldq %%xmm2, %%xmm0\n\t"	"punpckldq %%xmm3, %%xmm1\n\t"\
		"movdqa	%5, %%xmm2\n\t"		"pxor	%%xmm3, %%xmm3\n\t"\
		"punpcklqdq %%xmm0, %%xmm0\n\t"	"punpcklqdq %%xmm1, %%xmm1\n\t"\
		"pandn	%%xmm2, %%xmm1\n\t"\
		"psubq	%%xmm1, %%xmm3\n\t"\
		"pand	%%xmm0, %%xmm1\n\t"\
		"pand	%%xmm1, %%xmm3\n\t"	"pcmpeqd %%xmm0, %%xmm0\n\t"\
		"pshufd	$177, %%xmm3, %%xmm1\n\t"\
		"pcmpeqd %%xmm3, %%xmm1\n\t"\
		"psubq	%%xmm0, %%xmm1\n\t"\
		"psubq	%%xmm1, %%xmm3\n\t"\
		"pand	%%xmm2, %%xmm3\n\t"\
		"pshufd	$78, %%xmm3, %%xmm1\n\t"\
		"por	%%xmm1, %%xmm3\n\t"\
		"movd	%%xmm3, %%edx\n\t"	"psrlq	$32, %%xmm3\n\t"\
		"orl	%%edx, %%eax\n\t"	"movd	%%xmm3, %%edx"\
	: "=A" (flipped)\
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask), "a" (flip_l))

#define FLIP_CARRY_AB12(next)	__asm__(\
		"movd	%1, %%xmm0\n\t"		"movd	%3, %%xmm1\n\t"\
		"movd	%2, %%xmm2\n\t"		"movd	%4, %%xmm3\n\t"\
		"punpckldq %%xmm2, %%xmm0\n\t"	"punpckldq %%xmm3, %%xmm1\n\t"\
		"movdqa	%5, %%xmm2\n\t"		"pxor	%%xmm3, %%xmm3\n\t"\
		"punpcklqdq %%xmm0, %%xmm0\n\t"	"punpcklqdq %%xmm1, %%xmm1\n\t"\
						"movdqa	%%xmm1, %%xmm5\n\t"\
		"pandn	%%xmm2, %%xmm1\n\t"	"movq	%6, %%xmm4\n\t"\
		"psubq	%%xmm1, %%xmm3\n\t"	"paddb	%%xmm4, %%xmm5\n\t"\
		"pand	%%xmm0, %%xmm1\n\t"	"pand	%%xmm0, %%xmm5\n\t"\
		"pand	%%xmm1, %%xmm3\n\t"	"psubusb %%xmm4, %%xmm5\n\t"\
		"pshufd	$177, %%xmm3, %%xmm1\n\t"\
		"pcmpeqd %%xmm3, %%xmm1\n\t"	"pcmpeqd %%xmm0, %%xmm0\n\t"\
		"psubq	%%xmm0, %%xmm1\n\t"\
		"psubq	%%xmm1, %%xmm3\n\t"\
		"pand	%%xmm2, %%xmm3\n\t"	"por	%%xmm5, %%xmm3\n\t"\
		"pshufd	$78, %%xmm3, %%xmm1\n\t"\
		"por	%%xmm1, %%xmm3\n\t"\
		"movd	%%xmm3, %%eax\n\t"	"psrlq	$32, %%xmm3\n\t"\
						"movd	%%xmm3, %%edx"\
	: "=A" (flipped)\
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask), "m" (X_TO_BIT[next]))

#define	FLIP_CARRY_3_VEC(flip_l)	__asm__ (\
		"movd	%1, %%xmm0\n\t"		"movd	%3, %%xmm1\n\t"		"pcmpeqd %%xmm6, %%xmm6\n\t"\
		"movd	%2, %%xmm2\n\t"		"movd	%4, %%xmm3\n\t"\
		"punpckldq %%xmm2, %%xmm0\n\t"	"punpckldq %%xmm3, %%xmm1\n\t"\
		"movdqa	%5, %%xmm2\n\t"		"movq	%6, %%xmm5\n\t"\
		"punpcklqdq %%xmm0, %%xmm0\n\t"	"punpcklqdq %%xmm1, %%xmm1\n\t"\
		"movdqa	%%xmm0, %%xmm3\n\t"	"movdqa	%%xmm1, %%xmm4\n\t"\
		"por	%%xmm2, %%xmm1\n\t"	"por	%%xmm5, %%xmm4\n\t"\
		"psubq	%%xmm6, %%xmm1\n\t"	"psubq	%%xmm6, %%xmm4\n\t"\
		"pand	%%xmm1, %%xmm0\n\t"	"pand	%%xmm4, %%xmm3\n\t"\
		"movdqa	%%xmm2, %%xmm1\n\t"	"movdqa	%%xmm5, %%xmm4\n\t"\
		"pandn	%%xmm0, %%xmm1\n\t"	"pandn	%%xmm3, %%xmm4\n\t"\
		"pshufd	$177, %%xmm1, %%xmm0\n\t"	"pshuflw $78, %%xmm4, %%xmm3\n\t"\
		"pcmpeqd %%xmm1, %%xmm0\n\t"	"pcmpeqd %%xmm4, %%xmm3\n\t"\
		"paddq	%%xmm6, %%xmm1\n\t"	"paddq	%%xmm6, %%xmm4\n\t"\
		"psubq	%%xmm0, %%xmm1\n\t"	"psubq	%%xmm3, %%xmm4\n\t"\
		"pandn	%%xmm1, %%xmm2\n\t"	"pandn	%%xmm4, %%xmm5\n\t"\
		"pshufd	$78, %%xmm2, %%xmm0\n\t"\
		"por	%%xmm2, %%xmm0\n\t"	"por	%%xmm5, %%xmm0\n\t"\
		"movd	%%xmm0, %%edx\n\t"	"psrlq	$32, %%xmm0\n\t"\
		"orl	%%edx, %%eax\n\t"	"movd	%%xmm0, %%edx"\
	: "=A" (flipped)\
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask01), "m" (mask2), "a" (flip_l))

#define FLIP_CARRY_GH12	__asm__(\
		"movd	%4, %%xmm3\n\t"		"movd	%2, %%xmm2\n\t"\
		"movd	%3, %%xmm1\n\t"		"movd	%1, %%xmm0\n\t"		"pcmpeqd %%xmm4, %%xmm4\n\t"\
		"punpckldq %%xmm3, %%xmm1\n\t"	"punpckldq %%xmm2, %%xmm0\n\t"\
		"punpcklqdq %%xmm1, %%xmm1\n\t"	"punpcklqdq %%xmm0, %%xmm0\n\t"\
		"movdqa	%%xmm1, %%xmm3\n\t"	"pandn	%5, %%xmm3\n\t"		"pxor	%%xmm2, %%xmm2\n\t"\
		"pandn	%6, %%xmm1\n\t"		"psubq	%%xmm3, %%xmm2\n\t"\
		"cvtdq2pd %%xmm1, %%xmm1\n\t"	"pand	%%xmm0, %%xmm3\n\t"\
		"andpd	%7, %%xmm1\n\t"		"pand	%%xmm3, %%xmm2\n\t"\
		"cvtpd2dq %%xmm1, %%xmm1\n\t"	"pshufd	$177, %%xmm2, %%xmm3\n\t"\
		"pand	%%xmm1, %%xmm0\n\t"	"pcmpeqd %%xmm2, %%xmm3\n\t"\
						"psubq	%%xmm4, %%xmm3\n\t"\
		"pmullw	%8, %%xmm0\n\t"		"psubq	%%xmm3, %%xmm2\n\t"\
		"pand	%6, %%xmm0\n\t"		"pand	%5, %%xmm2\n\t"\
		"por	%%xmm2, %%xmm0\n\t"\
		"pshufd	$78, %%xmm0, %%xmm1\n\t"\
		"por	%%xmm1, %%xmm0\n\t"\
		"pshufd	$177, %%xmm0, %%xmm1\n\t"\
		"movd	%%xmm0, %%eax\n\t"\
		"movd	%%xmm1, %%edx"\
	: "=A" (flipped)\
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (expmask), "m" (minustwo))

#define FLIP_MS1B_2_VEC	__asm__(\
		"movd	%2, %%xmm3\n\t"		"movd	%4, %%xmm2\n\t"\
		"movd	%1, %%xmm1\n\t"		"movd	%3, %%xmm0\n\t"\
		"punpckldq %%xmm3, %%xmm1\n\t"	"punpckldq %%xmm2, %%xmm0\n\t"\
		"movapd	%6, %%xmm2\n\t"\
		"punpcklqdq %%xmm1, %%xmm1\n\t"	"punpcklqdq %%xmm0, %%xmm0\n\t"\
		"pandn	%5, %%xmm0\n\t"\
		"orpd	%%xmm2, %%xmm0\n\t"\
		"subpd	%%xmm2, %%xmm0\n\t"\
		"andpd	%7, %%xmm0\n\t"\
		"addpd	%%xmm2, %%xmm0\n\t"\
		"pand	%%xmm0, %%xmm1\n\t"\
		"pxor	%%xmm0, %%xmm0\n\t"\
		"paddq	%%xmm1, %%xmm1\n\t"\
		"psubq	%%xmm1, %%xmm0\n\t"\
		"pand	%5, %%xmm0\n\t"\
		"pshufd	$78, %%xmm0, %%xmm1\n\t"\
		"por	%%xmm1, %%xmm0\n\t"\
		"pshufd	$177, %%xmm0, %%xmm1\n\t"\
		"movd	%%xmm0, %%eax\n\t"\
		"movd	%%xmm1, %%edx\n\t"\
	: "=A" (flipped)\
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (k1e52), "m" (expmask))

#define FLIP_MS1B_AB78(next)	__asm__(\
		"movd	%2, %%xmm3\n\t"		"movd	%4, %%xmm2\n\t"\
		"movd	%1, %%xmm1\n\t"		"movd	%3, %%xmm0\n\t"\
		"punpckldq %%xmm3, %%xmm1\n\t"	"punpckldq %%xmm2, %%xmm0\n\t"\
		"movapd	%6, %%xmm2\n\t"\
		"punpcklqdq %%xmm1, %%xmm1\n\t"	"punpcklqdq %%xmm0, %%xmm0\n\t"\
						"movdqa	%%xmm0, %%xmm3\n\t"\
		"pandn	%5, %%xmm0\n\t"		"movq	%8, %%xmm4\n\t"\
		"orpd	%%xmm2, %%xmm0\n\t"	"paddb	%%xmm4, %%xmm3\n\t"\
		"subpd	%%xmm2, %%xmm0\n\t"	"pand	%%xmm1, %%xmm3\n\t"\
		"andpd	%7, %%xmm0\n\t"		"psubusb %%xmm4, %%xmm3\n\t"\
		"addpd	%%xmm2, %%xmm0\n\t"\
		"pand	%%xmm0, %%xmm1\n\t"\
		"pxor	%%xmm0, %%xmm0\n\t"\
		"paddq	%%xmm1, %%xmm1\n\t"\
		"psubq	%%xmm1, %%xmm0\n\t"\
		"pand	%5, %%xmm0\n\t"		"por	%%xmm3, %%xmm0\n\t"\
		"pshufd	$78, %%xmm0, %%xmm1\n\t"\
		"por	%%xmm1, %%xmm0\n\t"\
		"pshufd	$177, %%xmm0, %%xmm1\n\t"\
		"movd	%%xmm0, %%eax\n\t"\
		"movd	%%xmm1, %%edx\n\t"\
	: "=A" (flipped)\
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (k1e52), "m" (expmask), "m" (X_TO_BIT[next]))

#endif // hasSSE2

#endif // has| USE_GAS_MMX | _P_IX86

/**
 * Compute flipped discs when playing on square A1.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_A1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned char outflank_h;
	UINT64 flipped, outflank_v, outflank_d9;

	outflank_v = ((ULL(OH, OL) | ~0x0101010101010100) + 1) & ULL(PH, PL) & 0x0101010101010000;
	flipped = OutflankToFlipmask(outflank_v) & 0x0101010101010100;

	outflank_h = (OL + 0x02) & PL;
	flipped |= ((outflank_h * 0xff) >> 8) & 0x7e;

	outflank_d9 = ((ULL(OH, OL) | ~0x8040201008040200) + 1) & ULL(PH, PL) & 0x8040201008040000;
	flipped |= OutflankToFlipmask(outflank_d9) & 0x8040201008040200;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_A1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x0101010101010100, 0x8040201008040200 }};
	UINT64 flipped;

	FLIP_CARRY_AB12(1);

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square B1.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_B1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned char outflank_h;
	UINT64 flipped, outflank_v, outflank_d9;

	outflank_v = ((ULL(OH, OL) | ~0x0202020202020200) + 1) & ULL(PH, PL) & 0x0202020202020000;
	flipped = OutflankToFlipmask(outflank_v) & 0x0202020202020200;

	outflank_h = (OL + 0x04) & PL;
	flipped |= ((outflank_h * 0xff) >> 8) & 0x7c;

	outflank_d9 = ((ULL(OH, OL) | ~0x0080402010080400) + 1) & ULL(PH, PL) & 0x0080402010080000;
	flipped |= OutflankToFlipmask(outflank_d9) & 0x0080402010080400;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_B1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x0202020202020200, 0x0080402010080400 }};
	UINT64 flipped;

	FLIP_CARRY_AB12(2);

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square C1.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_C1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d9;

	outflank_v = ((ULL(OH, OL) | ~0x0404040404040400) + 1) & ULL(PH, PL) & 0x0404040404040400;
	flipped = OutflankToFlipmask(outflank_v) & 0x0404040404040400;

	outflank_h = OUTFLANK_2[(OL >> 1) & 0x3f] & PL;
	flipped |= (unsigned char) FLIPPED_2_H[outflank_h];

	flipped |= ((PL >> 7) & 0x00000200u & OL);

	outflank_d9 = ((ULL(OH, OL) | ~0x0000804020100800) + 1) & ULL(PH, PL) & 0x0000804020100800;
	flipped |= OutflankToFlipmask(outflank_d9) & 0x0000804020100800;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_C1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x0404040404040400, 0x0000804020100800 }};
	unsigned int outflank_h = OUTFLANK_2[(OL >> 1) & 0x3f] & PL;
	UINT64 flipped;

	FLIP_CARRY_2_VEC((unsigned char) FLIPPED_2_H[outflank_h] | ((PL >> 7) & 0x00000200u & OL));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square D1.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_D1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_d;
	UINT64 flipped, outflank_v;

	outflank_v = ((ULL(OH, OL) | ~0x0808080808080800) + 1) & ULL(PH, PL) & 0x0808080808080800;
	flipped = OutflankToFlipmask(outflank_v) & 0x0808080808080800;

	outflank_h = OUTFLANK_3[(OL >> 1) & 0x3f] & PL;
	flipped |= (unsigned char) FLIPPED_3_H[outflank_h];

	outflank_d = OUTFLANK_3[((OL & 0x40221400u) * 0x01010101u) >> 25]
		& ((((PH & 0x00000080u) + (PL & 0x41221400u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_3_H[outflank_d] & 0x40221400u;	// A4D1H5

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_D1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x0808080808080800, 0x0000008040201000 }};
	unsigned int outflank_h = OUTFLANK_3[(OL >> 1) & 0x3f] & PL;
	unsigned int outflank_d7 = ((OL | ~0x01020400u) + 1) & PL & 0x01020400u;
	UINT64 flipped;

	FLIP_CARRY_2_VEC((unsigned char) FLIPPED_3_H[outflank_h]
		| ((outflank_d7 - (unsigned int) (outflank_d7 != 0)) & 0x01020400u));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square E1.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_E1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_d;
	UINT64 flipped, outflank_v;

	outflank_v = ((ULL(OH, OL) | ~0x1010101010101000) + 1) & ULL(PH, PL) & 0x1010101010101000;
	flipped = OutflankToFlipmask(outflank_v) & 0x1010101010101000;

	outflank_h = OUTFLANK_4[(OL >> 1) & 0x3f] & PL;
	flipped |= (unsigned char) FLIPPED_4_H[outflank_h];

	outflank_d = OUTFLANK_4[((OL & 0x02442800u) * 0x01010101u) >> 25]
		& ((((PH & 0x00000001u) + (PL & 0x82442800u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_4_H[outflank_d] & 0x82442800u;	// A5E1H4

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_E1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x1010101010101000, 0x0000000102040800 }};
	unsigned int outflank_h = OUTFLANK_4[(OL >> 1) & 0x3f] & PL;
	unsigned int outflank_d9 = ((OL | ~0x80402000u) + 1) & PL & 0x80402000u;
	UINT64 flipped;

	FLIP_CARRY_2_VEC((unsigned char) FLIPPED_4_H[outflank_h]
		| ((outflank_d9 - (unsigned int) (outflank_d9 != 0)) & 0x80402000u));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square F1.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_F1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d7;

	outflank_v = ((ULL(OH, OL) | ~0x2020202020202000) + 1) & ULL(PH, PL) & 0x2020202020202000;
	flipped = OutflankToFlipmask(outflank_v) & 0x2020202020202000;

	outflank_h = OUTFLANK_5[(OL >> 1) & 0x3f] & PL;
	flipped |= (unsigned char) FLIPPED_5_H[outflank_h];

	outflank_d7 = ((ULL(OH, OL) | ~0x0000010204081000) + 1) & ULL(PH, PL) & 0x0000010204080000;
	flipped |= OutflankToFlipmask(outflank_d7) & 0x0000000204081000;

	flipped |= ((PL >> 9) & 0x00004000u & OL);

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_F1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x2020202020202000, 0x0000010204081000 }};
	unsigned int outflank_h = OUTFLANK_5[(OL >> 1) & 0x3f] & PL;
	UINT64 flipped;

	FLIP_CARRY_2_VEC((unsigned char) FLIPPED_5_H[outflank_h] | ((PL >> 9) & 0x00004000u & OL));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square G1.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_G1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d7;

	outflank_v = ((ULL(OH, OL) | ~0x4040404040404000) + 1) & ULL(PH, PL) & 0x4040404040400000;
	flipped = OutflankToFlipmask(outflank_v) & 0x4040404040404000;

	outflank_h = OUTFLANK_7[OL & 0x3e] & (PL << 1);
	flipped |= ((-outflank_h) & 0x3e) << 0;

	outflank_d7 = ((ULL(OH, OL) | ~0x0001020408102000) + 1) & ULL(PH, PL) & 0x0001020408100000;
	flipped |= OutflankToFlipmask(outflank_d7) & 0x0001020408102000;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_G1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x4040404040404000, 0x0001020408102000 }};
	static const V2DI mask2 = {{ 0x000000000000003f, 0 }};
	UINT64 flipped;

	FLIP_CARRY_GH12;

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square H1.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_H1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d7;

	outflank_v = ((ULL(OH, OL) | ~0x8080808080808000) + 1) & ULL(PH, PL) & 0x8080808080800000;
	flipped = OutflankToFlipmask(outflank_v) & 0x8080808080808000;

	outflank_h = OUTFLANK_7[(OL >> 1) & 0x3f] & PL;
	flipped |= ((-outflank_h) & 0x3f) << 1;

	outflank_d7 = ((ULL(OH, OL) | ~0x0102040810204000) + 1) & ULL(PH, PL) & 0x0102040810200000;
	flipped |= OutflankToFlipmask(outflank_d7) & 0x0102040810204000;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_H1(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x8080808080808000, 0x0102040810204000 }};
	static const V2DI mask2 = {{ 0x000000000000007f, 0 }};
	UINT64 flipped;

	FLIP_CARRY_GH12;

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square A2.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_A2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned short outflank_h;
	UINT64 flipped, outflank_v, outflank_d9;

	outflank_v = ((ULL(OH, OL) | ~0x0101010101010000) + 1) & ULL(PH, PL) & 0x0101010101000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x0101010101010000;

	outflank_h = (OL + 0x0200) & PL;
	flipped |= (outflank_h - (outflank_h >> 8)) & 0x00007e00;

	outflank_d9 = ((ULL(OH, OL) | ~0x4020100804020000) + 1) & ULL(PH, PL) & 0x4020100804000000;
	flipped |= OutflankToFlipmask(outflank_d9) & 0x4020100804020000;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_A2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x0101010101010000, 0x4020100804020000 }};
	UINT64 flipped;

	FLIP_CARRY_AB12(9);

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square B2.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_B2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned short outflank_h;
	UINT64 flipped, outflank_v, outflank_d9;

	outflank_v = ((ULL(OH, OL) | ~0x0202020202020000) + 1) & ULL(PH, PL) & 0x0202020202000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x0202020202020000;

	outflank_h = (OL + 0x0400) & PL;
	flipped |= (outflank_h - (outflank_h >> 8)) & 0x00007c00;

	outflank_d9 = ((ULL(OH, OL) | ~0x8040201008040000) + 1) & ULL(PH, PL) & 0x8040201008000000;
	flipped |= OutflankToFlipmask(outflank_d9) & 0x8040201008040000;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_B2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x0202020202020000, 0x8040201008040000 }};
	UINT64 flipped;

	FLIP_CARRY_AB12(10);

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square C2.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_C2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d9;

	outflank_v = ((ULL(OH, OL) | ~0x0404040404040000) + 1) & ULL(PH, PL) & 0x0404040404000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x0404040404040000;

	outflank_h = OUTFLANK_2[(OL >> 9) & 0x3f] & (PL >> 8);
	flipped |= (unsigned int) FLIPPED_2_H[outflank_h] & 0x0000ff00u;

	flipped |= ((PL >> 7) & 0x00020000u & OL);

	outflank_d9 = ((ULL(OH, OL) | ~0x0080402010080000) + 1) & ULL(PH, PL) & 0x0080402010080000;
	flipped |= OutflankToFlipmask(outflank_d9) & 0x0000402010080000;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_C2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x0404040404040000, 0x0080402010080000 }};
	unsigned int outflank_h = OUTFLANK_2[(OL >> 9) & 0x3f] & (PL >> 8);
	UINT64 flipped;

	FLIP_CARRY_2_VEC(((unsigned char) FLIPPED_2_H[outflank_h] << 8) | ((PL >> 7) & 0x00020000u & OL));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square D2.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_D2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_d;
	UINT64 flipped, outflank_v;

	outflank_v = ((ULL(OH, OL) | ~0x0808080808080000) + 1) & ULL(PH, PL) & 0x0808080808000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x0808080808080000;

	outflank_h = OUTFLANK_3[(OL >> 9) & 0x3f] & (PL >> 8);
	flipped |= (unsigned int) FLIPPED_3_H[outflank_h] & 0x0000ff00u;

	outflank_d = OUTFLANK_3[(((OH & 0x00000040u) + (OL & 0x22140000u)) * 0x01010101u) >> 25]
		& ((((PH & 0x00008041u) + (PL & 0x22140000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_3_H[outflank_d] & 0x0000004022140000;	// A5D2H6

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_D2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask01 = {{ ~0x0808080808080000, ~0x0000804020100000 }};
	static const UINT64 mask2 = ~0x0000000102040000;
	unsigned int outflank_h = OUTFLANK_3[(OL >> 9) & 0x3f] & (PL >> 8);
	UINT64 flipped;

	FLIP_CARRY_3_VEC((unsigned char) FLIPPED_3_H[outflank_h] << 8);

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square E2.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_E2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_d;
	UINT64 flipped, outflank_v;

	outflank_v = ((ULL(OH, OL) | ~0x1010101010100000) + 1) & ULL(PH, PL) & 0x1010101010000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x1010101010100000;

	outflank_h = OUTFLANK_4[(OL >> 9) & 0x3f] & (PL >> 8);
	flipped |= (unsigned int) FLIPPED_4_H[outflank_h] & 0x0000ff00u;

	outflank_d = OUTFLANK_4[(((OH & 0x00000002u) + (OL & 0x44280000u)) * 0x01010101u) >> 25]
		& ((((PH & 0x00000182u) + (PL & 0x44280000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_4_H[outflank_d] & 0x0000000244280000;	// A6E2H5

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_E2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask01 = {{ ~0x1010101010100000, ~0x0000010204080000 }};
	static const UINT64 mask2 = ~0x0000008040200000;
	unsigned int outflank_h = OUTFLANK_4[(OL >> 9) & 0x3f] & (PL >> 8);
	UINT64 flipped;

	FLIP_CARRY_3_VEC((unsigned char) FLIPPED_4_H[outflank_h] << 8);

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square F2.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_F2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d7;

	outflank_v = ((ULL(OH, OL) | ~0x2020202020200000) + 1) & ULL(PH, PL) & 0x2020202020000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x2020202020200000;

	outflank_h = OUTFLANK_5[(OL >> 9) & 0x3f] & (PL >> 8);
	flipped |= (unsigned int) FLIPPED_5_H[outflank_h] & 0x0000ff00u;

	outflank_d7 = ((ULL(OH, OL) | ~0x0001020408100000) + 1) & ULL(PH, PL) & 0x0001020408000000;
	flipped |= OutflankToFlipmask(outflank_d7) & 0x0000020408100000;

	flipped |= ((PL >> 9) & 0x00400000u & OL);

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_F2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x2020202020200000, 0x0001020408100000 }};
	unsigned int outflank_h = OUTFLANK_5[(OL >> 9) & 0x3f] & (PL >> 8);
	UINT64 flipped;

	FLIP_CARRY_2_VEC(((unsigned char) FLIPPED_5_H[outflank_h] << 8) | ((PL >> 9) & 0x00400000u & OL));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square G2.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_G2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d7;

	outflank_v = ((ULL(OH, OL) | ~0x4040404040400000) + 1) & ULL(PH, PL) & 0x4040404040000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x4040404040400000;

	outflank_h = OUTFLANK_7[(OL >> 8) & 0x3e] & (PL >> 7);
	flipped |= ((-outflank_h) & 0x3e) << 8;

	outflank_d7 = ((ULL(OH, OL) | ~0x0102040810200000) + 1) & ULL(PH, PL) & 0x0102040810000000;
	flipped |= OutflankToFlipmask(outflank_d7) & 0x0102040810200000;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_G2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x4040404040400000, 0x0102040810200000 }};
	static const V2DI mask2 = {{ 0x0000000000003f00, 0 }};
	UINT64 flipped;

	FLIP_CARRY_GH12;

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square H2.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_H2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d7;

	outflank_v = ((ULL(OH, OL) | ~0x8080808080800000) + 1) & ULL(PH, PL) & 0x8080808080000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x8080808080800000;

	outflank_h = OUTFLANK_7[(OL >> 9) & 0x3f] & (PL >> 8);
	flipped |= ((-outflank_h) & 0x3f) << 9;

	outflank_d7 = ((ULL(OH, OL) | ~0x0204081020400000) + 1) & ULL(PH, PL) & 0x0204081020000000;
	flipped |= OutflankToFlipmask(outflank_d7) & 0x0204081020400000;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_H2(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x8080808080800000, 0x0204081020400000 }};
	static const V2DI mask2 = {{ 0x0000000000007f00, 0 }};
	UINT64 flipped;

	FLIP_CARRY_GH12;

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square A3.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_A3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d9;

	outflank_v = ((ULL(OH, OL) | ~0x0101010101000000) + 1) & ULL(PH, PL) & 0x0101010101000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x0101010101000000;

	outflank_h = ((OL & 0x007e0000u) + 0x00020000u) & PL;
	flipped |= (outflank_h - (outflank_h >> 8)) & 0x007e0000u;

	outflank_d9 = ((ULL(OH, OL) | ~0x2010080402000000) + 1) & ULL(PH, PL) & 0x2010080400000000;
	flipped |= OutflankToFlipmask(outflank_d9) & 0x0010080402000000;

	flipped |= OL & (((PL << 8) & 0x00000100u) | ((PL << 7) & 0x00000200u));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_A3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x0101010101000000, 0x2010080402000000 }};
	unsigned int outflank_h = ((OL & 0x007e0000u) + 0x00020000u) & PL;
	UINT64 flipped;

	FLIP_CARRY_2_VEC(((outflank_h - (outflank_h >> 8)) & 0x007e0000u)
		| (OL & (((PL << 8) & 0x00000100u) | ((PL << 7) & 0x00000200u))));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square B3.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_B3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d9;

	outflank_v = ((ULL(OH, OL) | ~0x0202020202000000) + 1) & ULL(PH, PL) & 0x0202020202000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x0202020202000000;

	outflank_h = ((OL & 0x007c0000u) + 0x00040000u) & PL;
	flipped |= (outflank_h - (outflank_h >> 8)) & 0x007c0000u;

	outflank_d9 = ((ULL(OH, OL) | ~0x4020100804000000) + 1) & ULL(PH, PL) & 0x4020100800000000;
	flipped |= OutflankToFlipmask(outflank_d9) & 0x0020100804000000;

	flipped |= OL & (((PL << 8) & 0x00000200u) | ((PL << 7) & 0x00000400u));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_B3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x0202020202000000, 0x4020100804000000 }};
	unsigned int outflank_h = ((OL & 0x007c0000u) + 0x00040000u) & PL;
	UINT64 flipped;

	FLIP_CARRY_2_VEC(((outflank_h - (outflank_h >> 8)) & 0x007c0000u)
		| (OL & (((PL << 8) & 0x00000200u) | ((PL << 7) & 0x00000400u))));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square C3.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_C3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d9;

	outflank_v = ((ULL(OH, OL) | ~0x0404040404000000) + 1) & ULL(PH, PL) & 0x0404040404000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x0404040404000000;

	outflank_h = OUTFLANK_2[(OL >> 17) & 0x3f] & (PL >> 16);
	flipped |= (unsigned int) FLIPPED_2_H[outflank_h] & 0x00ff0000u;

	outflank_d9 = ((ULL(OH, OL) | ~0x8040201008000000) + 1) & ULL(PH, PL) & 0x8040201008000000;
	flipped |= OutflankToFlipmask(outflank_d9) & 0x8040201008000000;

	flipped |= OL & (((PL << 8) & 0x00000400u)
			| ((PL << 9) & 0x00000200u)
			| (((PH << 25) | (PL << 7)) & 0x02000800u));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_C3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x0404040404000000, 0x8040201008000000 }};
	unsigned int outflank_h = OUTFLANK_2[(OL >> 17) & 0x3f] & (PL >> 16);
	UINT64 flipped;

	FLIP_CARRY_2_VEC(((unsigned char) FLIPPED_2_H[outflank_h] << 16)
		| (OL & (((PL << 8) & 0x00000400u)
			| ((PL << 9) & 0x00000200u)
			| (((PH << 25) | (PL << 7)) & 0x02000800u))));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square D3.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_D3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_d;
	UINT64 flipped, outflank_v;

	outflank_v = ((ULL(OH, OL) | ~0x0808080808000000) + 1) & ULL(PH, PL) & 0x0808080808000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x0808080808000000;

	outflank_h = OUTFLANK_3[(OL >> 17) & 0x3f] & (PL >> 16);
	flipped |= (unsigned int) FLIPPED_3_H[outflank_h] & 0x00ff0000u;

	outflank_d = OUTFLANK_3[(((OH & 0x00004022u) + (OL & 0x14080000u)) * 0x01010101u) >> 25]
		& ((((PH & 0x00804122u) + (PL & 0x14080000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_3_H[outflank_d] & 0x0000402214080000;	// A6D3H7

	flipped |= OL & (((PL << 8) & 0x00000800u)
			| ((PL << 7) & 0x00001000u)
			| ((PL << 9) & 0x00000400u));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_D3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask01 = {{ ~0x0808080808000000, ~0x0080402010000000 }};
	static const UINT64 mask2 = ~0x0000010204000000;
	unsigned int outflank_h = OUTFLANK_3[(OL >> 17) & 0x3f] & (PL >> 16);
	UINT64 flipped;

	FLIP_CARRY_3_VEC(((unsigned char) FLIPPED_3_H[outflank_h] << 16)
		| (OL & (((PL << 8) & 0x00000800u)
			| ((PL << 7) & 0x00001000u)
			| ((PL << 9) & 0x00000400u))));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square E3.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_E3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_d;
	UINT64 flipped, outflank_v;

	outflank_v = ((ULL(OH, OL) | ~0x1010101010000000) + 1) & ULL(PH, PL) & 0x1010101010000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x1010101010000000;

	outflank_h = OUTFLANK_4[(OL >> 17) & 0x3f] & (PL >> 16);
	flipped |= (unsigned int) FLIPPED_4_H[outflank_h] & 0x00ff0000u;

	outflank_d = OUTFLANK_4[(((OH & 0x00000244u) + (OL & 0x28100000u)) * 0x01010101u) >> 25]
		& ((((PH & 0x00018244u) + (PL & 0x28100000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_4_H[outflank_d] & 0x0000024428100000;	// A7E7H6

	flipped |= OL & (((PL << 8) & 0x00001000u)
			| ((PL << 7) & 0x00002000u)
			| ((PL << 9) & 0x00000800u));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_E3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask01 = {{ ~0x1010101010000000, ~0x0001020408000000 }};
	static const UINT64 mask2 = ~0x0000804020000000;
	unsigned int outflank_h = OUTFLANK_4[(OL >> 17) & 0x3f] & (PL >> 16);
	UINT64 flipped;

	FLIP_CARRY_3_VEC(((unsigned char) FLIPPED_4_H[outflank_h] << 16)
		| (OL & (((PL << 8) & 0x00001000u)
			| ((PL << 7) & 0x00002000u)
			| ((PL << 9) & 0x00000800u))));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square F3.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_F3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d7;

	outflank_v = ((ULL(OH, OL) | ~0x2020202020000000) + 1) & ULL(PH, PL) & 0x2020202020000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x2020202020000000;

	outflank_h = OUTFLANK_5[(OL >> 17) & 0x3f] & (PL >> 16);
	flipped |= (unsigned int) FLIPPED_5_H[outflank_h] & 0x00ff0000u;

	outflank_d7 = ((ULL(OH, OL) | ~0x0102040810000000) + 1) & ULL(PH, PL) & 0x0102040810000000;
	flipped |= OutflankToFlipmask(outflank_d7) & 0x0102040810000000;

	flipped |= OL & (((PL << 8) & 0x00002000u)
			| ((PL << 7) & 0x00004000u)
			| (((PH << 23) | (PL << 9)) & 0x40001000u));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_F3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask = {{ 0x2020202020000000, 0x0102040810000000 }};
	unsigned int outflank_h = OUTFLANK_5[(OL >> 17) & 0x3f] & (PL >> 16);
	UINT64 flipped;

	FLIP_CARRY_2_VEC(((unsigned char) FLIPPED_5_H[outflank_h] << 16)
		| (OL & (((PL << 8) & 0x00002000u)
			| ((PL << 7) & 0x00004000u)
			| (((PH << 23) | (PL << 9)) & 0x40001000u))));

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square G3.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_G3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d7;

	outflank_v = ((ULL(OH, OL) | ~0x4040404040000000) + 1) & ULL(PH, PL) & 0x4040404040000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x4040404040000000;

	outflank_h = OUTFLANK_7[(OL >> 16) & 0x3e] & (PL >> 15);
	flipped |= ((-outflank_h) & 0x3e) << 16;

	outflank_d7 = ((ULL(OH, OL) | ~0x0204081020000000) + 1) & ULL(PH, PL) & 0x0204081000000000;
	flipped |= OutflankToFlipmask(outflank_d7) & 0x0004081020000000;

	flipped |= OL & (((PL << 8) & 0x00004000u) | ((PL << 9) & 0x00002000u));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_G3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x4040404040000000, 0x0204081020000000 }};
	static const V2DI mask2 = {{ 0x0000000000000040, 0x0000000000000010 }};
	static const V2DI mask3 = {{ 0x00000000003f0000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined(USE_MSVC_X86)
	__m128i OO = set1_by_movd(OL, OH);
	__m128i PP = set1_by_movd(PL, PH);
	__m128i	outflank_vd, outflank_h, flipped_v2, flipped_h2g2;

	outflank_vd = _mm_andnot_si128(OO, mask1.v2);
	outflank_vd = _mm_and_si128(_mm_and_si128(outflank_vd, _mm_sub_epi64(_mm_setzero_si128(), outflank_vd)), PP);
	flipped_v2 = _mm_and_si128(mask1.v2, _mm_sub_epi64(outflank_vd, _mm_sub_epi64(flipmask(outflank_vd), minusone)));

	flipped_h2g2 = _mm_mullo_epi16(_mm_and_si128(PP, mask2.v2), k02000100.v2);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_and_si128(flipped_h2g2, OO));

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(OO, mask3.v2)), PP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minus0800.v2), 10));

	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));
#else
	__asm__(\
		"movd	%4, %%xmm4\n\t"		"movd	%1, %%xmm1\n\t"
		"movd	%3, %%xmm5\n\t"		"movd	%2, %%xmm0\n\t"
		"punpckldq %%xmm4, %%xmm5\n\t"	"punpckldq %%xmm0, %%xmm1\n\t"
		"punpcklqdq %%xmm5, %%xmm5\n\t"	"punpcklqdq %%xmm1, %%xmm1\n\t"
						"pxor	%%xmm3, %%xmm3\n\t"
						"movdqa	%%xmm5, %%xmm4\n\t"
						"pandn	%5, %%xmm4\n\t"
		"movdqa	%%xmm5, %%xmm2\n\t"	"movdqa	%%xmm1, %%xmm0\n\t"
		"pandn	%7, %%xmm2\n\t"		"psubq	%%xmm4, %%xmm3\n\t"
		"cvtdq2pd %%xmm2, %%xmm2\n\t"	"pand	%%xmm4, %%xmm0\n\t"
		"andpd	%8, %%xmm2\n\t"		"pand	%%xmm0, %%xmm3\n\t"	"movdqa	%6, %%xmm0\n\t"
		"cvtpd2dq %%xmm2, %%xmm2\n\t"	"pshufd	$177, %%xmm3, %%xmm4\n\t"
						"pcmpeqd %%xmm3, %%xmm4\n\t"	"pand	%%xmm1, %%xmm0\n\t"
		"pand	%%xmm2, %%xmm1\n\t"	"pcmpeqd %%xmm2, %%xmm2\n\t"	"pmullw	%10, %%xmm0\n\t"
		"pmullw	%9, %%xmm1\n\t"		"psubq	%%xmm2, %%xmm4\n\t"	"pand	%%xmm5, %%xmm0\n\t"
		"psrlw	$10, %%xmm1\n\t"	"psubq	%%xmm4, %%xmm3\n\t"
		"por	%%xmm1, %%xmm0\n\t"	"pand	%5, %%xmm3\n\t"
		"por	%%xmm3, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm3\n\t"
		"por	%%xmm3, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (mask3), "m" (expmask), "m" (minus0800), "m" (k02000100));
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square H3.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_H3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h;
	UINT64 flipped, outflank_v, outflank_d7;

	outflank_v = ((ULL(OH, OL) | ~0x8080808080000000) + 1) & ULL(PH, PL) & 0x8080808080000000;
	flipped = OutflankToFlipmask(outflank_v) & 0x8080808080000000;

	outflank_h = OUTFLANK_7[(OL >> 17) & 0x3f] & (PL >> 16);
	flipped |= ((-outflank_h) & 0x3f) << 17;

	outflank_d7 = ((ULL(OH, OL) | ~0x0408102040000000) + 1) & ULL(PH, PL) & 0x0408102000000000;
	flipped |= OutflankToFlipmask(outflank_d7) & 0x0008102040000000;

	flipped |= OL & (((PL << 8) & 0x00008000u) | ((PL << 9) & 0x00004000u));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_H3(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x8080808080000000, 0x0408102040000000 }};
	static const V2DI mask2 = {{ 0x0000000000000080, 0x0000000000000020 }};
	static const V2DI mask3 = {{ 0x00000000007f0000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined(USE_MSVC_X86)
	__m128i OO = set1_by_movd(OL, OH);
	__m128i PP = set1_by_movd(PL, PH);
	__m128i	outflank_vd, outflank_h, flipped_v2, flipped_h2g2;

	outflank_vd = _mm_andnot_si128(OO, mask1.v2);
	outflank_vd = _mm_and_si128(_mm_and_si128(outflank_vd, _mm_sub_epi64(_mm_setzero_si128(), outflank_vd)), PP);
	flipped_v2 = _mm_and_si128(mask1.v2, _mm_sub_epi64(outflank_vd, _mm_sub_epi64(flipmask(outflank_vd), minusone)));

	flipped_h2g2 = _mm_mullo_epi16(_mm_and_si128(PP, mask2.v2), k02000100.v2);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_and_si128(flipped_h2g2, OO));

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(OO, mask3.v2)), PP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minus0400.v2), 9));

	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));
#else
	__asm__(\
		"movd	%4, %%xmm4\n\t"		"movd	%1, %%xmm1\n\t"
		"movd	%3, %%xmm5\n\t"		"movd	%2, %%xmm0\n\t"
		"punpckldq %%xmm4, %%xmm5\n\t"	"punpckldq %%xmm0, %%xmm1\n\t"
		"punpcklqdq %%xmm5, %%xmm5\n\t"	"punpcklqdq %%xmm1, %%xmm1\n\t"
						"pxor	%%xmm3, %%xmm3\n\t"
						"movdqa	%%xmm5, %%xmm4\n\t"
						"pandn	%5, %%xmm4\n\t"
		"movdqa	%%xmm5, %%xmm2\n\t"	"movdqa	%%xmm1, %%xmm0\n\t"
		"pandn	%7, %%xmm2\n\t"		"psubq	%%xmm4, %%xmm3\n\t"
		"cvtdq2pd %%xmm2, %%xmm2\n\t"	"pand	%%xmm4, %%xmm0\n\t"
		"andpd	%8, %%xmm2\n\t"		"pand	%%xmm0, %%xmm3\n\t"	"movdqa	%6, %%xmm0\n\t"
		"cvtpd2dq %%xmm2, %%xmm2\n\t"	"pshufd	$177, %%xmm3, %%xmm4\n\t"
						"pcmpeqd %%xmm3, %%xmm4\n\t"	"pand	%%xmm1, %%xmm0\n\t"
		"pand	%%xmm2, %%xmm1\n\t"	"pcmpeqd %%xmm2, %%xmm2\n\t"	"pmullw	%10, %%xmm0\n\t"
		"pmullw	%9, %%xmm1\n\t"		"psubq	%%xmm2, %%xmm4\n\t"	"pand	%%xmm5, %%xmm0\n\t"
		"psrlw	$9, %%xmm1\n\t"		"psubq	%%xmm4, %%xmm3\n\t"
		"por	%%xmm1, %%xmm0\n\t"	"pand	%5, %%xmm3\n\t"
		"por	%%xmm3, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm3\n\t"
		"por	%%xmm3, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (mask3), "m" (expmask), "m" (minus0400), "m" (k02000100));
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square A4.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_A4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, flip_d7, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_3[(((OL & 0x01010100u) + ((OH & 0x00010101u) << 4)) * 0x01020408u) >> 25]
		& ((((PL & 0x01010101u) + ((PH & 0x01010101u) << 4)) * 0x01020408u) >> 24);
	flipped = FLIPPED_3_V[outflank_v] & 0x0001010101010100;

	outflank_h = (OL + 0x02000000u) & PL;
	flipped |= (outflank_h - (outflank_h >> 8)) & 0x7e000000u;

	flip_d7 = OL & 0x00020000u;
	flip_d7 |= (flip_d7 >> 7) & OL;
	flipped |= flip_d7 & -(flip_d7 & (PL << 7));

	outflank_d9 = ((OH | ~0x10080402u) + 1) & PH & 0x10080400u;
	flipped |= (UINT64) ((outflank_d9 - (unsigned int) (outflank_d9 != 0)) & 0x00080402u) << 32;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_A4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0101010101010101, 0x1008040201020408 }};
	UINT64 flipped;
	unsigned int outflank_h;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	unsigned int outflank_v, outflank_d, index_v, index_d;
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, mask_d;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 7));
	outflank_v = OUTFLANK_3[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_3[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_3_V[outflank_v], &FLIPPED_3_V[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$7, %%xmm0\n\t"				"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"pmovmskb %%xmm1, %%eax\n\t"
		"movl	%%edx, %%ecx\n\t"			"movl	%%eax, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_3(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_3_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_3_V(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = (OL + 0x02000000u) & PL;
	return flipped | ((outflank_h - (outflank_h >> 8)) & 0x7e000000u);
}
#endif

/**
 * Compute flipped discs when playing on square B4.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_B4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, flip_d7, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_3[(((OL & 0x02020200u) + ((OH & 0x00020202u) << 4)) * 0x00810204u) >> 25]
		& ((((PL & 0x02020202u) + ((PH & 0x02020202u) << 4)) * 0x00810204u) >> 24);
	flipped = FLIPPED_3_V[outflank_v] & 0x0002020202020200;

	outflank_h = (OL + 0x04000000u) & PL;
	flipped |= (outflank_h - (outflank_h >> 8)) & 0x7c000000u;

	flip_d7 = OL & 0x00040000u;
	flip_d7 |= (flip_d7 >> 7) & OL;
	flipped |= flip_d7 & -(flip_d7 & (PL << 7));

	outflank_d9 = ((OH | ~0x20100804u) + 1) & PH & 0x20100800u;
	flipped |= (UINT64) ((outflank_d9 - (unsigned int) (outflank_d9 != 0)) & 0x00100804u) << 32;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_B4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0202020202020202, 0x2010080402040810 }};
	UINT64 flipped;
	unsigned int outflank_h;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 6));
	outflank_v = OUTFLANK_3[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_3[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_3_V[outflank_v], &FLIPPED_3_V[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$6, %%xmm0\n\t"				"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"pmovmskb %%xmm1, %%eax\n\t"
		"movl	%%edx, %%ecx\n\t"			"movl	%%eax, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_3(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_3_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_3_V(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = (OL + 0x04000000u) & PL;
	return flipped | ((outflank_h - (outflank_h >> 8)) & 0x7c000000u);
}
#endif

/**
 * Compute flipped discs when playing on square C4.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_C4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_3[(((OL & 0x04040400u) + ((OH & 0x00040404u) << 4)) * 0x00408102u) >> 25]
		& ((((PL & 0x04040404u) + ((PH & 0x04040404u) << 4)) * 0x00408102u) >> 24);
	flipped = FLIPPED_3_V[outflank_v] & 0x0004040404040400;

	outflank_h = OUTFLANK_2[(OL >> 25) & 0x3f] & (PL >> 24);
	flipped |= (unsigned int) FLIPPED_2_H[outflank_h] & 0xff000000u;

	outflank_d7 = OUTFLANK_2[(((OL & 0x04081000u) + (OH & 0x00000002u)) * 0x01010101u) >> 25]
		& ((((PL & 0x04081020u) + (PH & 0x00000102u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_2_H[outflank_d7] & 0x0000000204081000;

	outflank_d9 = OUTFLANK_2[(((OL & 0x04020000u) + (OH & 0x00201008u)) * 0x01010101u) >> 25]
		& ((((PL & 0x04020100u) + (PH & 0x40201008u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_2_H[outflank_d9] & 0x0020100804020000;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_C4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0404040404040404, 0x4020100804081020 }};
	UINT64 flipped;
	unsigned int outflank_h;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 5));
	outflank_v = OUTFLANK_3[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_3[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_3_V[outflank_v], &FLIPPED_3_V[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$5, %%xmm0\n\t"				"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"pmovmskb %%xmm1, %%eax\n\t"
		"movl	%%edx, %%ecx\n\t"			"movl	%%eax, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_3(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_3_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_3_V(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = OUTFLANK_2[(OL >> 25) & 0x3f] & (PL >> 24);
	return flipped | ((UINT64) (OH & (PH >> 7) & 0x00000002u) << 32)
		| ((OL & (PL << 9) & 0x00020000u)
		| ((unsigned char) FLIPPED_2_H[outflank_h] << 24));
}
#endif

/**
 * Compute flipped discs when playing on square D4.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_D4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_3[(((OL & 0x08080800u) + ((OH & 0x00080808u) << 4)) * 0x00204081u) >> 25]
		& ((((PL & 0x08080808u) + ((PH & 0x08080808u) << 4)) * 0x00204081u) >> 24);
	flipped = FLIPPED_3_V[outflank_v] & 0x0008080808080800;

	outflank_h = OUTFLANK_3[(OL >> 25) & 0x3f] & (PL >> 24);
	flipped |= (unsigned int) FLIPPED_3_H[outflank_h] & 0xff000000u;

	outflank_d7 = OUTFLANK_3[(((OL & 0x08102000u) + (OH & 0x00000204u)) * 0x01010101u) >> 25]
		& ((((PL & 0x08102040u) + (PH & 0x00010204u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_3_H[outflank_d7] & 0x0000020408102000;

	outflank_d9 = OUTFLANK_3[(((OL & 0x08040200u) + (OH & 0x00402010u)) * 0x01010101u) >> 25]
		& ((((PL & 0x08040201u) + (PH & 0x80402010u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_3_H[outflank_d9] & 0x0040201008040200;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_D4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x00000000ff000000, 0x0808080808080808 }};
	static const V2DI mask2 = {{ 0x0001020408102040, 0x8040201008040201 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i flipped_v2, flipped_d, mask_d7, mask_d9;
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9, index_v, index_d7, index_d9;
	__m128i	Z2 = _mm_setzero_si128();

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 4));
	outflank_h = OUTFLANK_3[(OL >> 25) & 0x3f] & (PL >> 24);
	outflank_v = OUTFLANK_3[(index_v >> 9) & 0x3f] & index_v;
	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_3_H[outflank_h], &FLIPPED_3_V[outflank_v]), mask1.v2);

	mask_d7 = _mm_shuffle_epi32(mask2.v2, DUPLO);
	index_d7 = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d7), mask_d7));
	outflank_d7 = OUTFLANK_3[(index_d7 >> 9) & 0x1f] & index_d7;

	mask_d9 = _mm_shuffle_epi32(mask2.v2, DUPHI);
	index_d9 = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d9), mask_d9));
	outflank_d9 = OUTFLANK_3[(index_d9 >> 9) & 0x3f] & index_d9;

	flipped_d = load64x2(&FLIPPED_3_V[outflank_d7], &FLIPPED_3_V[outflank_d9]);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_and_si128(flipped_d, mask2.v2));
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm6\n\t"				"movd	%4, %%xmm5\n\t"
		"punpckldq %%xmm6, %%xmm1\n\t"			"punpckldq %%xmm5, %%xmm0\n\t"
		"movl	%3, %%eax\n\t"				"punpcklqdq %%xmm0, %%xmm1\n\t"
		"shrl	$25, %%eax\n\t"				"movdqa	%%xmm1, %%xmm0\n\t"
		"movdqa	%6, %%xmm4\n\t"				"psllq	$4, %%xmm0\n\t"
		"andl	$63, %%eax\n\t"				"pmovmskb %%xmm0, %%edx\n\t"
		"movzbl	"_"OUTFLANK_3(%%eax), %%ecx\n\t"	"movl	%%edx, %%ebx\n\t"
		"movl	%1, %%eax\n\t"				"shrl	$9, %%ebx\n\t"
		"shrl	$24, %%eax\n\t"				"andl	$63, %%ebx\n\t"
		"andl	%%ecx, %%eax\n\t"			"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
								"andl	%%ebx, %%edx\n\t"
		"movq	"_"FLIPPED_3_H(,%%eax,8), %%xmm3\n\t"	"movhps	"_"FLIPPED_3_V(,%%edx,8), %%xmm3\n\t"
		"movdqa	%%xmm1, %%xmm2\n\t"			"movdqa	%%xmm1, %%xmm6\n\t"
		"pshufd	$68, %%xmm4, %%xmm0\n\t"		"pshufd	$238, %%xmm4, %%xmm5\n\t"
		"pand	%%xmm0, %%xmm2\n\t"			"pand	%%xmm5, %%xmm6\n\t"
		"pcmpeqb %%xmm2, %%xmm0\n\t"			"pcmpeqb %%xmm5, %%xmm6\n\t"
		"pmovmskb %%xmm0, %%eax\n\t"			"pmovmskb %%xmm6, %%ebx\n\t"
		"movl	%%eax, %%ecx\n\t"			"movl	%%ebx, %%edx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%edx\n\t"
		"andl	$31, %%ecx\n\t"				"andl	$63, %%edx\n\t"
		"movzbl	"_"OUTFLANK_3(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_3(%%edx), %%edx\n\t"
		"andl	%%ecx, %%eax\n\t"			"andl	%%edx, %%ebx\n\t"
		"movq	"_"FLIPPED_3_V(,%%eax,8), %%xmm2\n\t"	"movhps	"_"FLIPPED_3_V(,%%ebx,8), %%xmm2\n\t"
		"movdqa	%5, %%xmm1\n\t"
		"pand	%%xmm3, %%xmm1\n\t"			"pand	%%xmm2, %%xmm4\n\t"
		"por	%%xmm1, %%xmm4\n\t"
		"pshufd	$78, %%xmm4, %%xmm1\n\t"
		"por	%%xmm1, %%xmm4\n\t"
		"pshufd	$177, %%xmm4, %%xmm1\n\t"
		"movd	%%xmm4, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2)
	: "ebx", "ecx");
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square E3.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_E4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_3[((((OL & 0x10101000u) >> 4) + (OH & 0x00101010u)) * 0x01020408u) >> 25]
		& (((((PL & 0x10101010u) >> 4) + (PH & 0x10101010u)) * 0x01020408u) >> 24);
	flipped = FLIPPED_3_V[outflank_v] & 0x0010101010101000;

	outflank_h = OUTFLANK_4[(OL >> 25) & 0x3f] & (PL >> 24);
	flipped |= (unsigned int) FLIPPED_4_H[outflank_h] & 0xff000000u;

	outflank_d7 = OUTFLANK_4[(((OL & 0x10204000u) + (OH & 0x00020408u)) * 0x01010101u) >> 25]
		& ((((PL & 0x10204080u) + (PH & 0x01020408u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_4_H[outflank_d7] & 0x0002040810204000;

	outflank_d9 = OUTFLANK_4[(((OL & 0x10080400u) + (OH & 0x00004020u)) * 0x01010101u) >> 25]
		& ((((PL & 0x10080402u) + (PH & 0x00804020u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_4_H[outflank_d9] & 0x0000402010080400;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_E4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x00000000ff000000, 0x1010101010101010 }};
	static const V2DI mask2 = {{ 0x0102040810204080, 0x0080402010080402 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i flipped_v2, flipped_d, mask_d7, mask_d9;
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9, index_v, index_d7, index_d9;
	__m128i	Z2 = _mm_setzero_si128();

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 3));
	outflank_h = OUTFLANK_4[(OL >> 25) & 0x3f] & (PL >> 24);
	outflank_v = OUTFLANK_3[(index_v >> 9) & 0x3f] & index_v;
	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_4_H[outflank_h], &FLIPPED_3_V[outflank_v]), mask1.v2);

	mask_d7 = _mm_shuffle_epi32(mask2.v2, DUPLO);
	index_d7 = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d7), mask_d7));
	outflank_d7 = OUTFLANK_3[(index_d7 >> 9) & 0x3f] & index_d7;

	mask_d9 = _mm_shuffle_epi32(mask2.v2, DUPHI);
	index_d9 = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d9), mask_d9));
	outflank_d9 = OUTFLANK_3[(index_d9 >> 9) & 0x1f] & index_d9;

	flipped_d = load64x2(&FLIPPED_3_V[outflank_d7], &FLIPPED_3_V[outflank_d9]);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_and_si128(flipped_d, mask2.v2));
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm6\n\t"				"movd	%4, %%xmm5\n\t"
		"punpckldq %%xmm6, %%xmm1\n\t"			"punpckldq %%xmm5, %%xmm0\n\t"
		"movl	%3, %%eax\n\t"				"punpcklqdq %%xmm0, %%xmm1\n\t"
		"shrl	$25, %%eax\n\t"				"movdqa	%%xmm1, %%xmm0\n\t"
		"movdqa	%6, %%xmm4\n\t"				"psllq	$3, %%xmm0\n\t"
		"andl	$63, %%eax\n\t"				"pmovmskb %%xmm0, %%edx\n\t"
		"movzbl	"_"OUTFLANK_4(%%eax), %%ecx\n\t"	"movl	%%edx, %%ebx\n\t"
		"movl	%1, %%eax\n\t"				"shrl	$9, %%ebx\n\t"
		"shrl	$24, %%eax\n\t"				"andl	$63, %%ebx\n\t"
		"andl	%%ecx, %%eax\n\t"			"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
								"andl	%%ebx, %%edx\n\t"
		"movq	"_"FLIPPED_4_H(,%%eax,8), %%xmm3\n\t"	"movhps	"_"FLIPPED_3_V(,%%edx,8), %%xmm3\n\t"
		"movdqa	%%xmm1, %%xmm2\n\t"			"movdqa	%%xmm1, %%xmm6\n\t"
		"pshufd	$68, %%xmm4, %%xmm0\n\t"		"pshufd	$238, %%xmm4, %%xmm5\n\t"
		"pand	%%xmm0, %%xmm2\n\t"			"pand	%%xmm5, %%xmm6\n\t"
		"pcmpeqb %%xmm2, %%xmm0\n\t"			"pcmpeqb %%xmm5, %%xmm6\n\t"
		"pmovmskb %%xmm0, %%eax\n\t"			"pmovmskb %%xmm6, %%ebx\n\t"
		"movl	%%eax, %%ecx\n\t"			"movl	%%ebx, %%edx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%edx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$31, %%edx\n\t"
		"movzbl	"_"OUTFLANK_3(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_3(%%edx), %%edx\n\t"
		"andl	%%ecx, %%eax\n\t"			"andl	%%edx, %%ebx\n\t"
		"movq	"_"FLIPPED_3_V(,%%eax,8), %%xmm2\n\t"	"movhps	"_"FLIPPED_3_V(,%%ebx,8), %%xmm2\n\t"
		"movdqa	%5, %%xmm1\n\t"
		"pand	%%xmm3, %%xmm1\n\t"			"pand	%%xmm2, %%xmm4\n\t"
		"por	%%xmm1, %%xmm4\n\t"
		"pshufd	$78, %%xmm4, %%xmm1\n\t"
		"por	%%xmm1, %%xmm4\n\t"
		"pshufd	$177, %%xmm4, %%xmm1\n\t"
		"movd	%%xmm4, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2)
	: "ebx", "ecx");
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square F4.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_F4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_3[((((OL & 0x20202000u) >> 4) + (OH & 0x00202020u)) * 0x00810204u) >> 25]
		& (((((PL & 0x20202020u) >> 4) + (PH & 0x20202020u)) * 0x00810204u) >> 24);
	flipped = FLIPPED_3_V[outflank_v] & 0x0020202020202000;

	outflank_h = OUTFLANK_5[(OL >> 25) & 0x3f] & (PL >> 24);
	flipped |= (unsigned int) FLIPPED_5_H[outflank_h] & 0xff000000u;

	outflank_d7 = OUTFLANK_5[(((OL & 0x20400000u) + (OH & 0x00040810u)) * 0x01010101u) >> 25]
		& ((((PL & 0x20408000u) + (PH & 0x02040810u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_5_H[outflank_d7] & 0x0004081020400000;

	outflank_d9 = OUTFLANK_5[(((OL & 0x20100800u) + (OH & 0x00000040u)) * 0x01010101u) >> 25]
		& ((((PL & 0x20100804u) + (PH & 0x00008040u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_5_H[outflank_d9] & 0x0000004020100800;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_F4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x2020202020202020, 0x0204081020100804 }};
	UINT64 flipped;
	unsigned int outflank_h;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 2));
	outflank_v = OUTFLANK_3[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_3[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_3_V[outflank_v], &FLIPPED_3_V[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$2, %%xmm0\n\t"				"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"pmovmskb %%xmm1, %%eax\n\t"
		"movl	%%edx, %%ecx\n\t"			"movl	%%eax, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_3(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_3_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_3_V(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = OUTFLANK_5[(OL >> 25) & 0x3f] & (PL >> 24);
	return flipped | ((UINT64) (OH & (PH >> 9) & 0x00000040u) << 32)
		| ((OL & (PL << 7) & 0x00400000u)
		| ((unsigned char) FLIPPED_5_H[outflank_h] << 24));
}
#endif

/**
 * Compute flipped discs when playing on square G4.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_G4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, flip_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_3[((((OL & 0x40404000u) >> 4) + (OH & 0x00404040u)) * 0x00408102u) >> 25]
		& (((((PL & 0x40404040u) >> 4) + (PH & 0x40404040u)) * 0x00408102u) >> 24);
	flipped = FLIPPED_3_V[outflank_v] & 0x0040404040404000;

	outflank_h = OUTFLANK_7[(OL >> 24) & 0x3e] & (PL >> 23);
	flipped |= ((-outflank_h) & 0x3e) << 24;

	outflank_d7 = ((OH | ~0x04081020u) + 1) & PH & 0x04081000u;
	flipped |= (UINT64) ((outflank_d7 - (unsigned int) (outflank_d7 != 0)) & 0x00081020u) << 32;

	flip_d9 = OL & 0x00200000u;
	flip_d9 |= (flip_d9 >> 9) & OL;
	flipped |= flip_d9 & -(flip_d9 & (PL << 9));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_G4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x4040404040404040, 0x0408102040201008 }};
	static const V2DI mask2 = {{ 0x000000003f000000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	outflank_h, flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 1));
	outflank_v = OUTFLANK_3[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_3[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_3_V[outflank_v], &FLIPPED_3_V[outflank_d]), mask1.v2);

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(_mm_shuffle_epi32(OP, DUPHI), mask2.v2)), OP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minuseight.v2), 2));
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%3, %%xmm1\n\t"		"movd	%1, %%xmm0\n\t"
		"movd	%4, %%xmm3\n\t"		"movd	%2, %%xmm4\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"	"punpckldq %%xmm4, %%xmm0\n\t"
		"punpcklqdq %%xmm1, %%xmm0\n\t"	"pshufd	$238, %5, %%xmm1\n\t"
		"movdqa	%%xmm0, %%xmm3\n\t"	"movdqa	%%xmm0, %%xmm2\n\t"	"pshufd	$238, %%xmm0, %%xmm4\n\t"
		"psllq	$1, %%xmm3\n\t"		"pand	%%xmm1, %%xmm2\n\t"	"pandn	%6, %%xmm4\n\t"
						"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm3, %%edx\n\t"	"pmovmskb %%xmm1, %%eax\n\t"	"cvtdq2pd %%xmm4, %%xmm4\n\t"
		"movl	%%edx, %%ecx\n\t"	"movl	%%eax, %%ebx\n\t"	"andpd	%7, %%xmm4\n\t"
		"shrl	$9, %%ecx\n\t"		"shrl	$9, %%ebx\n\t"		"cvtpd2dq %%xmm4, %%xmm4\n\t"
		"andl	$63, %%ecx\n\t"		"andl	$63, %%ebx\n\t"		"pand	%%xmm4, %%xmm0\n\t"
		"movzbl	"_"OUTFLANK_3(%%ecx), %%ecx\n\t"
						"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
		"andl	%%edx, %%ecx\n\t"	"andl	%%ebx, %%eax\n\t"	"pmullw	%8, %%xmm0\n\t"
		"movq	"_"FLIPPED_3_V(,%%ecx,8), %%xmm2\n\t"
						"movhps	"_"FLIPPED_3_V(,%%eax,8), %%xmm2\n\t"
		"pand	%5, %%xmm2\n\t"						"psrlw	$2, %%xmm0\n\t"
		"por	%%xmm2, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (expmask), "m" (minuseight)
	: "ebx", "ecx");
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square H4.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_H4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, flip_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_3[((((OL & 0x80808000u) >> 4) + (OH & 0x00808080u)) * 0x00204081u) >> 25]
		& (((((PL & 0x80808080u) >> 4) + (PH & 0x80808080u)) * 0x00204081u) >> 24);
	flipped = FLIPPED_3_V[outflank_v] & 0x0080808080808000;

	outflank_h = OUTFLANK_7[(OL >> 25) & 0x3f] & (PL >> 24);
	flipped |= ((-outflank_h) & 0x3f) << 25;

	outflank_d7 = ((OH | ~0x08102040u) + 1) & PH & 0x08102000u;
	flipped |= (UINT64) ((outflank_d7 - (unsigned int) (outflank_d7 != 0)) & 0x00102040u) << 32;

	flip_d9 = OL & 0x00400000u;
	flip_d9 |= (flip_d9 >> 9) & OL;
	flipped |= flip_d9 & -(flip_d9 & (PL << 9));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_H4(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x8080808080808080, 0x0810204080402010 }};
	static const V2DI mask2 = {{ 0x000000007f000000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	outflank_h, flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(OP);
	outflank_v = OUTFLANK_3[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_3[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_3_V[outflank_v], &FLIPPED_3_V[outflank_d]), mask1.v2);

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(_mm_shuffle_epi32(OP, DUPHI), mask2.v2)), OP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minusfour.v2), 1));
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%3, %%xmm1\n\t"		"movd	%1, %%xmm0\n\t"
		"movd	%4, %%xmm3\n\t"		"movd	%2, %%xmm4\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"	"punpckldq %%xmm4, %%xmm0\n\t"
		"punpcklqdq %%xmm1, %%xmm0\n\t"	"pshufd	$238, %5, %%xmm1\n\t"
		"movdqa	%%xmm0, %%xmm3\n\t"	"movdqa	%%xmm0, %%xmm2\n\t"	"pshufd	$238, %%xmm0, %%xmm4\n\t"
						"pand	%%xmm1, %%xmm2\n\t"	"pandn	%6, %%xmm4\n\t"
						"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm3, %%edx\n\t"	"pmovmskb %%xmm1, %%eax\n\t"	"cvtdq2pd %%xmm4, %%xmm4\n\t"
		"movl	%%edx, %%ecx\n\t"	"movl	%%eax, %%ebx\n\t"	"andpd	%7, %%xmm4\n\t"
		"shrl	$9, %%ecx\n\t"		"shrl	$9, %%ebx\n\t"		"cvtpd2dq %%xmm4, %%xmm4\n\t"
		"andl	$63, %%ecx\n\t"		"andl	$63, %%ebx\n\t"		"pand	%%xmm4, %%xmm0\n\t"
		"movzbl	"_"OUTFLANK_3(%%ecx), %%ecx\n\t"
						"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
		"andl	%%edx, %%ecx\n\t"	"andl	%%ebx, %%eax\n\t"	"pmullw	%8, %%xmm0\n\t"
		"movq	"_"FLIPPED_3_V(,%%ecx,8), %%xmm2\n\t"
						"movhps	"_"FLIPPED_3_V(,%%eax,8), %%xmm2\n\t"
		"pand	%5, %%xmm2\n\t"						"psrlw	$1, %%xmm0\n\t"
		"por	%%xmm2, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (expmask), "m" (minusfour)
	: "ebx", "ecx");
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square A5.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_A5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_v, flip_d7, outflank_d9;
	unsigned char outflank_h;
	UINT64 flipped;

	outflank_v = OUTFLANK_4[(((OL & 0x01010100u) + ((OH & 0x00010101u) << 4)) * 0x01020408u) >> 25]
		& ((((PL & 0x01010101u) + ((PH & 0x01010101u) << 4)) * 0x01020408u) >> 24);
	flipped = FLIPPED_4_V[outflank_v] & 0x0001010101010100;

	outflank_h = (OH + 0x02) & PH;
	flipped |= (UINT64) (((outflank_h * 0xff) >> 8) & 0x0000007eu) << 32;

	flip_d7 = OL & ((OL >> 7) | 0x02000000u);
	flip_d7 &= ((flip_d7 & 0x02040000u) >> 14) | 0x02040000u;
	flipped |= flip_d7 & -(flip_d7 & (PL << 7));

	outflank_d9 = ((OH | ~0x08040200u) + 1) & PH & 0x08040000u;
	flipped |= (UINT64) ((outflank_d9 - (unsigned int) (outflank_d9 != 0)) & 0x00040200u) << 32;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_A5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0101010101010101, 0x0804020102040810 }};
	UINT64 flipped;
	unsigned char outflank_h;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 7));
	outflank_v = OUTFLANK_4[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_4[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_4_V[outflank_v], &FLIPPED_4_V[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$7, %%xmm0\n\t"				"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"pmovmskb %%xmm1, %%eax\n\t"
		"movl	%%edx, %%ecx\n\t"			"movl	%%eax, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_4(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_4_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_4_V(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = (OH + 0x02) & PH;
	return  flipped | ((UINT64) (((outflank_h * 0xff) >> 8) & 0x0000007eu) << 32);
}
#endif

/**
 * Compute flipped discs when playing on square B5.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_B5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_v, flip_d7, outflank_d9;
	unsigned char outflank_h;
	UINT64 flipped;

	outflank_v = OUTFLANK_4[(((OL & 0x02020200u) + ((OH & 0x00020202u) << 4)) * 0x00810204u) >> 25]
		& ((((PL & 0x02020202u) + ((PH & 0x02020202u) << 4)) * 0x00810204u) >> 24);
	flipped = FLIPPED_4_V[outflank_v] & 0x0002020202020200;

	outflank_h = (OH + 0x04) & PH;
	flipped |= (UINT64) (((outflank_h * 0xff) >> 8) & 0x0000007cu) << 32;

	flip_d7 = OL & ((OL >> 7) | 0x04000000u);
	flip_d7 &= ((flip_d7 & 0x04080000u) >> 14) | 0x04080000u;
	flipped |= flip_d7 & -(flip_d7 & (PL << 7));

	outflank_d9 = ((OH | ~0x10080400u) + 1) & PH & 0x10080000u;
	flipped |= (UINT64) ((outflank_d9 - (unsigned int) (outflank_d9 != 0)) & 0x00080400u) << 32;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_B5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0202020202020202, 0x1008040204081020 }};
	UINT64 flipped;
	unsigned char outflank_h;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 6));
	outflank_v = OUTFLANK_4[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_4[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_4_V[outflank_v], &FLIPPED_4_V[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$6, %%xmm0\n\t"				"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"pmovmskb %%xmm1, %%eax\n\t"
		"movl	%%edx, %%ecx\n\t"			"movl	%%eax, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_4(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_4_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_4_V(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = (OH + 0x04) & PH;
	return  flipped | ((UINT64) (((outflank_h * 0xff) >> 8) & 0x0000007cu) << 32);
}
#endif

/**
 * Compute flipped discs when playing on square C5.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_C5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_4[(((OL & 0x04040400u) + ((OH & 0x00040404u) << 4)) * 0x00408102u) >> 25]
		& ((((PL & 0x04040404u) + ((PH & 0x04040404u) << 4)) * 0x00408102u) >> 24);
	flipped = FLIPPED_4_V[outflank_v] & 0x0004040404040400;

	outflank_h = OUTFLANK_2[(OH >> 1) & 0x3f] & (PH >> 0);
	flipped |= FLIPPED_2_H[outflank_h] & 0x000000ff00000000;

	outflank_d7 = OUTFLANK_2[(((OL & 0x08102000u) + (OH & 0x00000204u)) * 0x01010101u) >> 25]
		& ((((PL & 0x08102040u) + (PH & 0x00010204u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_2_H[outflank_d7] & 0x0000020408102000;

	outflank_d9 = OUTFLANK_2[(((OL & 0x02000000u) + (OH & 0x00100804u)) * 0x01010101u) >> 25]
		& ((((PL & 0x02010000u) + (PH & 0x20100804u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_2_H[outflank_d9] & 0x0010080402000000;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_C5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0404040404040404, 0x2010080408102040 }};
	UINT64 flipped;
	unsigned int outflank_h, FH;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 5));
	outflank_v = OUTFLANK_4[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_4[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_4_V[outflank_v], &FLIPPED_4_V[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$5, %%xmm0\n\t"				"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"pmovmskb %%xmm1, %%eax\n\t"
		"movl	%%edx, %%ecx\n\t"			"movl	%%eax, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_4(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_4_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_4_V(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = OUTFLANK_2[(OH >> 1) & 0x3f] & (PH >> 0);
	FH = (unsigned char) FLIPPED_2_H[outflank_h] | (OH & (PH >> 7) & 0x00000200u);
	return flipped | ((UINT64) FH << 32) | (OL & (PL << 9) & 0x02000000u);
}
#endif

/**
 * Compute flipped discs when playing on square D5.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_D5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_4[(((OL & 0x08080800u) + ((OH & 0x00080808u) << 4)) * 0x00204081u) >> 25]
		& ((((PL & 0x08080808u) + ((PH & 0x08080808u) << 4)) * 0x00204081u) >> 24);
	flipped = FLIPPED_4_V[outflank_v] & 0x0008080808080800;

	outflank_h = OUTFLANK_3[(OH >> 1) & 0x3f] & (PH >> 0);
	flipped |= FLIPPED_3_H[outflank_h] & 0x000000ff00000000;

	outflank_d7 = OUTFLANK_3[(((OL & 0x10204000u) + (OH & 0x00020408u)) * 0x01010101u) >> 25]
		& ((((PL & 0x10204080u) + (PH & 0x01020408u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_3_H[outflank_d7] & 0x0002040810204000;

	outflank_d9 = OUTFLANK_3[(((OL & 0x04020000u) + (OH & 0x00201008u)) * 0x01010101u) >> 25]
		& ((((PL & 0x04020100u) + (PH & 0x40201008u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_3_H[outflank_d9] & 0x0020100804020000;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_D5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x000000ff00000000, 0x0808080808080808 }};
	static const V2DI mask2 = {{ 0x4020100804020100, 0x0102040810204080 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i flipped_v2, flipped_d, mask_d7, mask_d9;
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9, index_v, index_d7, index_d9;
	__m128i	Z2 = _mm_setzero_si128();

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 4));
	outflank_h = OUTFLANK_3[(OH >> 1) & 0x3f] & PH;
	outflank_v = OUTFLANK_4[(index_v >> 9) & 0x3f] & index_v;
	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_3_H[outflank_h], &FLIPPED_4_V[outflank_v]), mask1.v2);

	mask_d7 = _mm_shuffle_epi32(mask2.v2, DUPLO);
	index_d7 = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d7), mask_d7));
	outflank_d7 = OUTFLANK_4[(index_d7 >> 9) & 0x3e] & index_d7;

	mask_d9 = _mm_shuffle_epi32(mask2.v2, DUPHI);
	index_d9 = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d9), mask_d9));
	outflank_d9 = OUTFLANK_4[(index_d9 >> 9) & 0x3f] & index_d9;

	flipped_d = load64x2(&FLIPPED_4_V[outflank_d7], &FLIPPED_4_V[outflank_d9]);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_and_si128(flipped_d, mask2.v2));
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm6\n\t"				"movd	%4, %%xmm5\n\t"
		"punpckldq %%xmm6, %%xmm1\n\t"			"punpckldq %%xmm5, %%xmm0\n\t"
		"movl	%4, %%eax\n\t"				"punpcklqdq %%xmm0, %%xmm1\n\t"
		"shrl	$1, %%eax\n\t"				"movdqa	%%xmm1, %%xmm0\n\t"
		"movdqa	%6, %%xmm4\n\t"				"psllq	$4, %%xmm0\n\t"
		"andl	$63, %%eax\n\t"				"pmovmskb %%xmm0, %%edx\n\t"
		"movzbl	"_"OUTFLANK_3(%%eax), %%ecx\n\t"	"movl	%%edx, %%ebx\n\t"
		"movl	%2, %%eax\n\t"				"shrl	$9, %%ebx\n\t"
								"andl	$63, %%ebx\n\t"
		"andl	%%ecx, %%eax\n\t"			"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
								"andl	%%ebx, %%edx\n\t"
		"movq	"_"FLIPPED_3_H(,%%eax,8), %%xmm3\n\t"	"movhps	"_"FLIPPED_4_V(,%%edx,8), %%xmm3\n\t"
		"movdqa	%%xmm1, %%xmm2\n\t"			"movdqa	%%xmm1, %%xmm6\n\t"
		"pshufd	$68, %%xmm4, %%xmm0\n\t"		"pshufd	$238, %%xmm4, %%xmm5\n\t"
		"pand	%%xmm0, %%xmm2\n\t"			"pand	%%xmm5, %%xmm6\n\t"
		"pcmpeqb %%xmm2, %%xmm0\n\t"			"pcmpeqb %%xmm5, %%xmm6\n\t"
		"pmovmskb %%xmm0, %%eax\n\t"			"pmovmskb %%xmm6, %%ebx\n\t"
		"movl	%%eax, %%ecx\n\t"			"movl	%%ebx, %%edx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%edx\n\t"
		"andl	$62, %%ecx\n\t"				"andl	$63, %%edx\n\t"
		"movzbl	"_"OUTFLANK_4(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_4(%%edx), %%edx\n\t"
		"andl	%%ecx, %%eax\n\t"			"andl	%%edx, %%ebx\n\t"
		"movq	"_"FLIPPED_4_V(,%%eax,8), %%xmm2\n\t"	"movhps	"_"FLIPPED_4_V(,%%ebx,8), %%xmm2\n\t"
		"movdqa	%5, %%xmm1\n\t"
		"pand	%%xmm3, %%xmm1\n\t"			"pand	%%xmm2, %%xmm4\n\t"
		"por	%%xmm1, %%xmm4\n\t"
		"pshufd	$78, %%xmm4, %%xmm1\n\t"
		"por	%%xmm1, %%xmm4\n\t"
		"pshufd	$177, %%xmm4, %%xmm1\n\t"
		"movd	%%xmm4, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2)
	: "ebx", "ecx");
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square E5.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_E5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_4[((((OL & 0x10101000u) >> 4) + (OH & 0x00101010u)) * 0x01020408u) >> 25]
		& (((((PL & 0x10101010u) >> 4) + (PH & 0x10101010u)) * 0x01020408u) >> 24);
	flipped = FLIPPED_4_V[outflank_v] & 0x0010101010101000;

	outflank_h = OUTFLANK_4[(OH >> 1) & 0x3f] & (PH >> 0);
	flipped |= FLIPPED_4_H[outflank_h] & 0x000000ff00000000;

	outflank_d7 = OUTFLANK_4[(((OL & 0x20400000u) + (OH & 0x00040810u)) * 0x01010101u) >> 25]
		& ((((PL & 0x20408000u) + (PH & 0x02040810u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_4_H[outflank_d7] & 0x0004081020400000;

	outflank_d9 = OUTFLANK_4[(((OL & 0x08040200u) + (OH & 0x00402010u)) * 0x01010101u) >> 25]
		& ((((PL & 0x08040201u) + (PH & 0x80402010u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_4_H[outflank_d9] & 0x0040201008040200;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_E5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x000000ff00000000, 0x1010101010101010 }};
	static const V2DI mask2 = {{ 0x8040201008040201, 0x0204081020408000 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i flipped_v2, flipped_d, mask_d7, mask_d9;
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9, index_v, index_d7, index_d9;
	__m128i	Z2 = _mm_setzero_si128();

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 3));
	outflank_h = OUTFLANK_4[(OH >> 1) & 0x3f] & PH;
	outflank_v = OUTFLANK_4[(index_v >> 9) & 0x3f] & index_v;
	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_4_H[outflank_h], &FLIPPED_4_V[outflank_v]), mask1.v2);

	mask_d7 = _mm_shuffle_epi32(mask2.v2, DUPLO);
	index_d7 = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d7), mask_d7));
	outflank_d7 = OUTFLANK_4[(index_d7 >> 9) & 0x3f] & index_d7;

	mask_d9 = _mm_shuffle_epi32(mask2.v2, DUPHI);
	index_d9 = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d9), mask_d9));
	outflank_d9 = OUTFLANK_4[(index_d9 >> 9) & 0x3e] & index_d9;

	flipped_d = load64x2(&FLIPPED_4_V[outflank_d7], &FLIPPED_4_V[outflank_d9]);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_and_si128(flipped_d, mask2.v2));
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm6\n\t"				"movd	%4, %%xmm5\n\t"
		"punpckldq %%xmm6, %%xmm1\n\t"			"punpckldq %%xmm5, %%xmm0\n\t"
		"movl	%4, %%eax\n\t"				"punpcklqdq %%xmm0, %%xmm1\n\t"
		"shrl	$1, %%eax\n\t"				"movdqa	%%xmm1, %%xmm0\n\t"
		"movdqa	%6, %%xmm4\n\t"				"psllq	$3, %%xmm0\n\t"
		"andl	$63, %%eax\n\t"				"pmovmskb %%xmm0, %%edx\n\t"
		"movzbl	"_"OUTFLANK_4(%%eax), %%ecx\n\t"	"movl	%%edx, %%ebx\n\t"
		"movl	%2, %%eax\n\t"				"shrl	$9, %%ebx\n\t"
								"andl	$63, %%ebx\n\t"
		"andl	%%ecx, %%eax\n\t"			"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
								"andl	%%ebx, %%edx\n\t"
		"movq	"_"FLIPPED_4_H(,%%eax,8), %%xmm3\n\t"	"movhps	"_"FLIPPED_4_V(,%%edx,8), %%xmm3\n\t"
		"movdqa	%%xmm1, %%xmm2\n\t"			"movdqa	%%xmm1, %%xmm6\n\t"
		"pshufd	$68, %%xmm4, %%xmm0\n\t"		"pshufd	$238, %%xmm4, %%xmm5\n\t"
		"pand	%%xmm0, %%xmm2\n\t"			"pand	%%xmm5, %%xmm6\n\t"
		"pcmpeqb %%xmm2, %%xmm0\n\t"			"pcmpeqb %%xmm5, %%xmm6\n\t"
		"pmovmskb %%xmm0, %%eax\n\t"			"pmovmskb %%xmm6, %%ebx\n\t"
		"movl	%%eax, %%ecx\n\t"			"movl	%%ebx, %%edx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%edx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$62, %%edx\n\t"
		"movzbl	"_"OUTFLANK_4(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_4(%%edx), %%edx\n\t"
		"andl	%%ecx, %%eax\n\t"			"andl	%%edx, %%ebx\n\t"
		"movq	"_"FLIPPED_4_V(,%%eax,8), %%xmm2\n\t"	"movhps	"_"FLIPPED_4_V(,%%ebx,8), %%xmm2\n\t"
		"movdqa	%5, %%xmm1\n\t"
		"pand	%%xmm3, %%xmm1\n\t"			"pand	%%xmm2, %%xmm4\n\t"
		"por	%%xmm1, %%xmm4\n\t"
		"pshufd	$78, %%xmm4, %%xmm1\n\t"
		"por	%%xmm1, %%xmm4\n\t"
		"pshufd	$177, %%xmm4, %%xmm1\n\t"
		"movd	%%xmm4, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2)
	: "ebx", "ecx");
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square F5.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_F5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_4[((((OL & 0x20202000u) >> 4) + (OH & 0x00202020u)) * 0x00810204u) >> 25]
		& (((((PL & 0x20202020u) >> 4) + (PH & 0x20202020u)) * 0x00810204u) >> 24);
	flipped = FLIPPED_4_V[outflank_v] & 0x0020202020202000;

	outflank_h = OUTFLANK_5[(OH >> 1) & 0x3f] & (PH >> 0);
	flipped |= FLIPPED_5_H[outflank_h] & 0x000000ff00000000;

	outflank_d7 = OUTFLANK_5[(((OL & 0x40000000u) + (OH & 0x00081020u)) * 0x01010101u) >> 25]
		& ((((PL & 0x40800000u) + (PH & 0x04081020u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_5_H[outflank_d7] & 0x0008102040000000;

	outflank_d9 = OUTFLANK_5[(((OL & 0x10080400u) + (OH & 0x00004020u)) * 0x01010101u) >> 25]
		& ((((PL & 0x10080402u) + (PH & 0x00804020u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_5_H[outflank_d9] & 0x0000402010080400;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_F5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x2020202020202020, 0x0408102010080402 }};
	UINT64 flipped;
	unsigned int outflank_h, FH;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 2));
	outflank_v = OUTFLANK_4[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_4[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_4_V[outflank_v], &FLIPPED_4_V[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$2, %%xmm0\n\t"				"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"pmovmskb %%xmm1, %%eax\n\t"
		"movl	%%edx, %%ecx\n\t"			"movl	%%eax, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$9, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_4(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_4_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_4_V(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = OUTFLANK_5[(OH >> 1) & 0x3f] & (PH >> 0);
	FH = (unsigned char) FLIPPED_5_H[outflank_h] | (OH & (PH >> 9) & 0x00004000u);
	return flipped | ((UINT64) FH << 32) | (OL & (PL << 7) & 0x40000000u);
}
#endif

/**
 * Compute flipped discs when playing on square G5.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_G5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, flip_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_4[((((OL & 0x40404000u) >> 4) + (OH & 0x00404040u)) * 0x00408102u) >> 25]
		& (((((PL & 0x40404040u) >> 4) + (PH & 0x40404040u)) * 0x00408102u) >> 24);
	flipped = FLIPPED_4_V[outflank_v] & 0x0040404040404000;

	outflank_h = OUTFLANK_7[(OH >> 0) & 0x3e] & (PH << 1);
	flipped |= (UINT64) ((-outflank_h) & 0x3e) << 32;

	outflank_d7 = ((OH | ~0x08102000u) + 1) & PH & 0x08100000u;
	flipped |= (UINT64) ((outflank_d7 - (unsigned int) (outflank_d7 != 0)) & 0x00102000u) << 32;

	flip_d9 = OL & ((OL >> 9) | 0x20000000u);
	flip_d9 &= ((flip_d9 & 0x20100000u) >> 18) | 0x20100000u;
	flipped |= flip_d9 & -(flip_d9 & (PL << 9));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_G5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x4040404040404040, 0x0810204020100804 }};
	static const V2DI mask2 = {{ 0x0000003f00000000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	outflank_h, flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 1));
	outflank_v = OUTFLANK_4[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_4[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_4_V[outflank_v], &FLIPPED_4_V[outflank_d]), mask1.v2);

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(_mm_shuffle_epi32(OP, DUPHI), mask2.v2)), OP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minus0800.v2), 10));
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%3, %%xmm1\n\t"		"movd	%1, %%xmm0\n\t"
		"movd	%4, %%xmm3\n\t"		"movd	%2, %%xmm4\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"	"punpckldq %%xmm4, %%xmm0\n\t"
		"punpcklqdq %%xmm1, %%xmm0\n\t"	"pshufd	$238, %5, %%xmm1\n\t"
		"movdqa	%%xmm0, %%xmm3\n\t"	"movdqa	%%xmm0, %%xmm2\n\t"	"pshufd	$238, %%xmm0, %%xmm4\n\t"
		"psllq	$1, %%xmm3\n\t"		"pand	%%xmm1, %%xmm2\n\t"	"pandn	%6, %%xmm4\n\t"
						"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm3, %%edx\n\t"	"pmovmskb %%xmm1, %%eax\n\t"	"cvtdq2pd %%xmm4, %%xmm4\n\t"
		"movl	%%edx, %%ecx\n\t"	"movl	%%eax, %%ebx\n\t"	"andpd	%7, %%xmm4\n\t"
		"shrl	$9, %%ecx\n\t"		"shrl	$9, %%ebx\n\t"		"cvtpd2dq %%xmm4, %%xmm4\n\t"
		"andl	$63, %%ecx\n\t"		"andl	$63, %%ebx\n\t"		"pand	%%xmm4, %%xmm0\n\t"
		"movzbl	"_"OUTFLANK_4(%%ecx), %%ecx\n\t"
						"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
		"andl	%%edx, %%ecx\n\t"	"andl	%%ebx, %%eax\n\t"	"pmullw	%8, %%xmm0\n\t"
		"movq	"_"FLIPPED_4_V(,%%ecx,8), %%xmm2\n\t"
						"movhps	"_"FLIPPED_4_V(,%%eax,8), %%xmm2\n\t"
		"pand	%5, %%xmm2\n\t"						"psrlw	$10, %%xmm0\n\t"
		"por	%%xmm2, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (expmask), "m" (minus0800)
	: "ebx", "ecx");
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square H5.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_H5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7, flip_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_4[((((OL & 0x80808000u) >> 4) + (OH & 0x00808080u)) * 0x00204081u) >> 25]
		& (((((PL & 0x80808080u) >> 4) + (PH & 0x80808080u)) * 0x00204081u) >> 24);
	flipped = FLIPPED_4_V[outflank_v] & 0x0080808080808000;

	outflank_h = OUTFLANK_7[(OH >> 1) & 0x3f] & (PH >> 0);
	flipped |= (UINT64) (((-outflank_h) & 0x3f) << 1) << 32;

	outflank_d7 = ((OH | ~0x10204000u) + 1) & PH & 0x10200000u;
	flipped |= (UINT64) ((outflank_d7 - (unsigned int) (outflank_d7 != 0)) & 0x00204000u) << 32;

	flip_d9 = OL & ((OL >> 9) | 0x40000000u);
	flip_d9 &= ((flip_d9 & 0x40200000u) >> 18) | 0x40200000u;
	flipped |= flip_d9 & -(flip_d9 & (PL << 9));

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_H5(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x8080808080808080, 0x1020408040201008 }};
	static const V2DI mask2 = {{ 0x0000007f00000000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	outflank_h, flipped_v2, mask_d;
	unsigned int outflank_v, outflank_d, index_v, index_d;

	index_v = _mm_movemask_epi8(OP);
	outflank_v = OUTFLANK_4[(index_v >> 9) & 0x3f] & index_v;

	mask_d = _mm_shuffle_epi32(mask1.v2, DUPHI);
	index_d = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_and_si128(OP, mask_d), mask_d));
	outflank_d = OUTFLANK_4[(index_d >> 9) & 0x3f] & index_d;

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_4_V[outflank_v], &FLIPPED_4_V[outflank_d]), mask1.v2);

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(_mm_shuffle_epi32(OP, DUPHI), mask2.v2)), OP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minus0400.v2), 9));
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%3, %%xmm1\n\t"		"movd	%1, %%xmm0\n\t"
		"movd	%4, %%xmm3\n\t"		"movd	%2, %%xmm4\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"	"punpckldq %%xmm4, %%xmm0\n\t"
		"punpcklqdq %%xmm1, %%xmm0\n\t"	"pshufd	$238, %5, %%xmm1\n\t"
		"movdqa	%%xmm0, %%xmm3\n\t"	"movdqa	%%xmm0, %%xmm2\n\t"	"pshufd	$238, %%xmm0, %%xmm4\n\t"
						"pand	%%xmm1, %%xmm2\n\t"	"pandn	%6, %%xmm4\n\t"
						"pcmpeqb %%xmm2, %%xmm1\n\t"
		"pmovmskb %%xmm3, %%edx\n\t"	"pmovmskb %%xmm1, %%eax\n\t"	"cvtdq2pd %%xmm4, %%xmm4\n\t"
		"movl	%%edx, %%ecx\n\t"	"movl	%%eax, %%ebx\n\t"	"andpd	%7, %%xmm4\n\t"
		"shrl	$9, %%ecx\n\t"		"shrl	$9, %%ebx\n\t"		"cvtpd2dq %%xmm4, %%xmm4\n\t"
		"andl	$63, %%ecx\n\t"		"andl	$63, %%ebx\n\t"		"pand	%%xmm4, %%xmm0\n\t"
		"movzbl	"_"OUTFLANK_4(%%ecx), %%ecx\n\t"
						"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
		"andl	%%edx, %%ecx\n\t"	"andl	%%ebx, %%eax\n\t"	"pmullw	%8, %%xmm0\n\t"
		"movq	"_"FLIPPED_4_V(,%%ecx,8), %%xmm2\n\t"
						"movhps	"_"FLIPPED_4_V(,%%eax,8), %%xmm2\n\t"
		"pand	%5, %%xmm2\n\t"						"psrlw	$9, %%xmm0\n\t"
		"por	%%xmm2, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (expmask), "m" (minus0400)
	: "ebx", "ecx");
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square A6.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_A6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_v, flip_d7;
	unsigned short outflank_h;
	UINT64 flipped;

	outflank_v = OUTFLANK_5[(((OL & 0x01010100u) + ((OH & 0x00010101u) << 4)) * 0x01020408u) >> 25]
		& ((((PL & 0x01010101u) + ((PH & 0x01010101u) << 4)) * 0x01020408u) >> 24);
	flipped = FLIPPED_5_V[outflank_v] & 0x0001010101010100;

	outflank_h = (OH + 0x0200) & PH;
	flipped |= (UINT64) ((outflank_h - (outflank_h >> 8)) & 0x00007e00u) << 32;

	flip_d7 = (OL >> 8) | (OH << 24);
	flip_d7 &= (flip_d7 >> 7) | 0x02000000u;
	flip_d7 &= ((flip_d7 & 0x02040000u) >> 14) | 0x02040000u;
	flipped |= (UINT64) (flip_d7 & -(flip_d7 & (PL >> 1))) << 8;

	flipped |= (UINT64) ((PH >> 9) & 0x00020000u & OH) << 32;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_A6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000000101010101, 0x0000000204081020 }};
	UINT64 flipped;
	unsigned int FH;
	unsigned short outflank_h;

	FLIP_MS1B_2_VEC;

	outflank_h = (OH + 0x0200) & PH;
	FH = ((outflank_h - (outflank_h >> 8)) & 0x00007e00u)
		| (OH & (((PH >> 8) & 0x00010000u) | ((PH >> 9) & 0x00020000u)));
	return flipped | ((UINT64) FH << 32);
}
#endif

/**
 * Compute flipped discs when playing on square B6.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_B6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_v, flip_d7;
	unsigned short outflank_h;
	UINT64 flipped;

	outflank_v = OUTFLANK_5[(((OL & 0x02020200u) + ((OH & 0x00020202u) << 4)) * 0x00810204u) >> 25]
		& ((((PL & 0x02020202u) + ((PH & 0x02020202u) << 4)) * 0x00810204u) >> 24);
	flipped = FLIPPED_5_V[outflank_v] & 0x0002020202020200;

	outflank_h = (OH + 0x0400) & PH;
	flipped |= (UINT64) ((outflank_h - (outflank_h >> 8)) & 0x00007c00u) << 32;

	flip_d7 = (OL >> 8) | (OH << 24);
	flip_d7 &= (flip_d7 >> 7) | 0x04000000u;
	flip_d7 &= ((flip_d7 & 0x04080000u) >> 14) | 0x04080000u;
	flipped |= (UINT64) (flip_d7 & -(flip_d7 & (PL >> 1))) << 8;

	flipped |= (UINT64) ((PH >> 9) & 0x00040000u & OH) << 32;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_B6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000000202020202, 0x0000000408102040 }};
	UINT64 flipped;
	unsigned int FH;
	unsigned short outflank_h;

	FLIP_MS1B_2_VEC;

	outflank_h = (OH + 0x0400) & PH;
	FH = ((outflank_h - (outflank_h >> 8)) & 0x00007c00u)
		| (OH & (((PH >> 8) & 0x00020000u) | ((PH >> 9) & 0x00040000u)));
	return flipped | ((UINT64) FH << 32);
}
#endif

/**
 * Compute flipped discs when playing on square C6.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_C6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d7;
	UINT64 flipped;

	outflank_v = OUTFLANK_5[(((OL & 0x04040400u) + ((OH & 0x00040404u) << 4)) * 0x00408102u) >> 25]
		& ((((PL & 0x04040404u) + ((PH & 0x04040404u) << 4)) * 0x00408102u) >> 24);
	flipped = FLIPPED_5_V[outflank_v] & 0x0004040404040400;

	outflank_h = OUTFLANK_2[(OH >> 9) & 0x3f] & (PH >> 8);
	flipped |= FLIPPED_2_H[outflank_h] & 0x0000ff0000000000;

	outflank_d7 = OUTFLANK_2[(((OL & 0x10204000u) + (OH & 0x00020408u)) * 0x01010101u) >> 25]
		& ((((PL & 0x10204080u) + (PH & 0x01020408u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_2_H[outflank_d7] & 0x0002040810204000;

	flipped |= (UINT64) (((PH >> 9) | (PL >> 23)) & 0x00080002u & OH) << 32;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_C6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000000404040404, 0x0000000810204080 }};
	UINT64 flipped;
	unsigned int outflank_h, FH;

	FLIP_MS1B_2_VEC;

	outflank_h = OUTFLANK_2[(OH >> 9) & 0x3f] & (PH >> 8);
	FH = ((unsigned char) FLIPPED_2_H[outflank_h] << 8)
		| (OH & (((PH >> 8) & 0x00040000u)
			| ((PH >> 7) & 0x00020000u)
			| (((PH >> 9) | (PL >> 23)) & 0x00080002u)));
	return flipped | ((UINT64) FH << 32);
}
#endif

/**
 * Compute flipped discs when playing on square D6.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_D6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d;
	UINT64 flipped;

	outflank_v = OUTFLANK_5[(((OL & 0x08080800u) + ((OH & 0x00080808u) << 4)) * 0x00204081u) >> 25]
		& ((((PL & 0x08080808u) + ((PH & 0x08080808u) << 4)) * 0x00204081u) >> 24);
	flipped = FLIPPED_5_V[outflank_v] & 0x0008080808080800;

	outflank_h = OUTFLANK_3[(OH >> 9) & 0x3f] & (PH >> 8);
	flipped |= FLIPPED_3_H[outflank_h] & 0x0000ff0000000000;

	outflank_d = OUTFLANK_3[(((OL & 0x22400000u) + (OH & 0x00000814u)) * 0x01010101u) >> 25]
		& ((((PL & 0x22418000u) + (PH & 0x00000814u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_3_H[outflank_d] & 0x0000081422400000;	// A3D6H2

	flipped |= (UINT64) (OH & (((PH >> 9) & 0x00100000u) | ((PH >> 7) & 0x00040000u))) << 32;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_D6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0808080808080808, 0x0000081422418000 }};	// A3D6H2
	UINT64 flipped;
	unsigned int outflank_h, FH;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, index_d;
	unsigned int outflank_v, outflank_d, index_v;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 4));
	outflank_v = OUTFLANK_5[(index_v >> 9) & 0x3f] & index_v;

	index_d = _mm_sad_epu8(_mm_and_si128(OP, _mm_shuffle_epi32(mask1.v2, DUPHI)), _mm_setzero_si128());
	outflank_d = OUTFLANK_3[(_mm_extract_epi16(index_d, 4) >> 1) & 0x3f] & _mm_cvtsi128_si32(index_d);

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_5_V[outflank_v], &FLIPPED_3_H[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$4, %%xmm0\n\t"				"pxor	%%xmm2, %%xmm2\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"psadbw %%xmm2, %%xmm1\n\t"
		"movl	%%edx, %%ecx\n\t"			"pextrw	$4, %%xmm1, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$1, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_5(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
								"movd	%%xmm1, %%eax\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_5_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_3_H(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif


	outflank_h = OUTFLANK_3[(OH >> 9) & 0x3f] & (PH >> 8);
	FH = ((unsigned char) FLIPPED_3_H[outflank_h] << 8)
		| (OH & (((PH >> 9) & 0x00100000u) | ((PH >> 7) & 0x00040000u)));
	return flipped | ((UINT64) FH << 32);
}
#endif

/**
 * Compute flipped discs when playing on square E6.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_E6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d;
	UINT64 flipped;

	outflank_v = OUTFLANK_5[((((OL & 0x10101000u) >> 4) + (OH & 0x00101010u)) * 0x01020408u) >> 25]
		& (((((PL & 0x10101010u) >> 4) + (PH & 0x10101010u)) * 0x01020408u) >> 24);
	flipped = FLIPPED_5_V[outflank_v] & 0x0010101010101000;

	outflank_h = OUTFLANK_4[(OH >> 9) & 0x3f] & (PH >> 8);
	flipped |= FLIPPED_4_H[outflank_h] & 0x0000ff0000000000;

	outflank_d = OUTFLANK_4[(((OL & 0x44020000u) + (OH & 0x00001028u)) * 0x01010101u) >> 25]
		& ((((PL & 0x44820100u) + (PH & 0x00001028u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_4_H[outflank_d] & 0x0000102844020000;	// A2E6H3

	flipped |= (UINT64) (OH & (((PH >> 9) & 0x00200000u) | ((PH >> 7) & 0x00080000u))) << 32;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_E6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x1010101010101010, 0x0000102844820100 }};	// A2E6H3
	UINT64 flipped;
	unsigned int outflank_h, FH;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, index_d;
	unsigned int outflank_v, outflank_d, index_v;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 3));
	outflank_v = OUTFLANK_5[(index_v >> 9) & 0x3f] & index_v;

	index_d = _mm_sad_epu8(_mm_and_si128(OP, _mm_shuffle_epi32(mask1.v2, DUPHI)), _mm_setzero_si128());
	outflank_d = OUTFLANK_4[(_mm_extract_epi16(index_d, 4) >> 1) & 0x3f] & _mm_cvtsi128_si32(index_d);

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_5_V[outflank_v], &FLIPPED_4_H[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$3, %%xmm0\n\t"				"pxor	%%xmm2, %%xmm2\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"psadbw %%xmm2, %%xmm1\n\t"
		"movl	%%edx, %%ecx\n\t"			"pextrw	$4, %%xmm1, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$1, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_5(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
								"movd	%%xmm1, %%eax\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_5_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_4_H(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = OUTFLANK_4[(OH >> 9) & 0x3f] & (PH >> 8);
	FH = ((unsigned char) FLIPPED_4_H[outflank_h] << 8)
		| (OH & (((PH >> 9) & 0x00200000u) | ((PH >> 7) & 0x00080000u)));

	return flipped | ((UINT64) FH << 32);
}
#endif

/**
 * Compute flipped discs when playing on square F6.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_F6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_5[((((OL & 0x20202000u) >> 4) + (OH & 0x00202020u)) * 0x00810204u) >> 25]
		& (((((PL & 0x20202020u) >> 4) + (PH & 0x20202020u)) * 0x00810204u) >> 24);
	flipped = FLIPPED_5_V[outflank_v] & 0x0020202020202000;

	outflank_h = OUTFLANK_5[(OH >> 9) & 0x3f] & (PH >> 8);
	flipped |= FLIPPED_5_H[outflank_h] & 0x0000ff0000000000;

	flipped |= (UINT64) (((PH >> 7) | (PL >> 25)) & 0x00100040u & OH) << 32;

	outflank_d9 = OUTFLANK_5[(((OL & 0x08040200u) + (OH & 0x00402010u)) * 0x01010101u) >> 25]
		& ((((PL & 0x08040201u) + (PH & 0x80402010u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_5_H[outflank_d9] & 0x0040201008040200;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_F6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000002020202020, 0x0000001008040201 }};
	UINT64 flipped;
	unsigned int outflank_h, FH;

	FLIP_MS1B_2_VEC;

	outflank_h = OUTFLANK_5[(OH >> 9) & 0x3f] & (PH >> 8);
	FH = ((unsigned char) FLIPPED_5_H[outflank_h] << 8)
		| (OH & (((PH >> 8) & 0x00200000u)
			| ((PH >> 9) & 0x00400000u)
			| (((PH >> 7) | (PL >> 25)) & 0x00100040u)));
	return flipped | ((UINT64) FH << 32);
}
#endif

/**
 * Compute flipped discs when playing on square G6.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_G6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, flip_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_5[((((OL & 0x40404000u) >> 4) + (OH & 0x00404040u)) * 0x00408102u) >> 25]
		& (((((PL & 0x40404040u) >> 4) + (PH & 0x40404040u)) * 0x00408102u) >> 24);
	flipped = FLIPPED_5_V[outflank_v] & 0x0040404040404000;

	outflank_h = OUTFLANK_7[(OH >> 8) & 0x3e] & (PH >> 7);
	flipped |= (UINT64) ((((-outflank_h) & 0x3e) << 8) | ((PH >> 7) & 0x00200000u & OH)) << 32;

	flip_d9 = (OL >> 8) | (OH << 24);
	flip_d9 &= (flip_d9 >> 9) | 0x20000000u;
	flip_d9 &= ((flip_d9 & 0x20100000u) >> 18) | 0x20100000u;
	flipped |= (UINT64) (flip_d9 & -(flip_d9 & (PL << 1))) << 8;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_G6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000004040404040, 0x0000002010080402 }};
	static const V2DI mask2 = {{ 0x0040000000000000, 0x0020000000000000 }};
	static const V2DI mask3 = {{ 0x00003f0000000000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i outflank_vd, outflank_h, flipped_v2, flipped_g7f7;
	__m128i PP = set1_by_movd(PL, PH);
	__m128i OO = set1_by_movd(OL, OH);

	outflank_vd = _mm_and_si128(MS1B_epi52(_mm_andnot_si128(OO, mask1.v2)), PP);
	flipped_v2 = _mm_and_si128(_mm_sub_epi64(_mm_setzero_si128(), _mm_add_epi64(outflank_vd, outflank_vd)), mask1.v2);

	flipped_g7f7 = _mm_and_si128(_mm_mulhi_epu16(PP, k02000100.v2), mask2.v2);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_and_si128(flipped_g7f7, OO));

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(OO, mask3.v2)), PP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minuseight.v2), 2));

	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%2, %%xmm4\n\t"		"movd	%3, %%xmm2\n\t"
		"movd	%1, %%xmm3\n\t"		"movd	%4, %%xmm0\n\t"
		"movapd	%10, %%xmm1\n\t"
		"punpckldq %%xmm4, %%xmm3\n\t"	"punpckldq %%xmm0, %%xmm2\n\t"
		"punpcklqdq %%xmm3, %%xmm3\n\t"	"punpcklqdq %%xmm2, %%xmm2\n\t"
		"movdqa	%%xmm2, %%xmm0\n\t"
		"pandn	%5, %%xmm0\n\t"					"movdqa	%11, %%xmm4\n\t"
		"orpd	%%xmm1, %%xmm0\n\t"				"pmulhuw %%xmm3, %%xmm4\n\t"
		"subpd	%%xmm1, %%xmm0\n\t"				"pand	%6, %%xmm4\n\t"
		"andpd	%8, %%xmm0\n\t"
		"addpd	%%xmm1, %%xmm0\n\t"	"movdqa	%%xmm2, %%xmm1\n\t"
						"pandn	%7, %%xmm1\n\t"
		"pand	%%xmm3, %%xmm0\n\t"	"cvtdq2pd %%xmm1, %%xmm1\n\t"
						"andpd	%8, %%xmm1\n\t"
		"paddq	%%xmm0, %%xmm0\n\t"	"cvtpd2dq %%xmm1, %%xmm1\n\t"
						"pand	%%xmm3, %%xmm1\n\t"
		"pxor	%%xmm3, %%xmm3\n\t"	"pmullw	%9, %%xmm1\n\t"
		"psubq	%%xmm0, %%xmm3\n\t"	"psrlq	$2, %%xmm1\n\t"
		"movdqa	%5, %%xmm0\n\t"
		"pand	%%xmm3, %%xmm0\n\t"				"pand	%%xmm2, %%xmm4\n\t"
		"por	%%xmm0, %%xmm1\n\t"				"por	%%xmm4, %%xmm1\n\t"
		"pshufd	$78, %%xmm1, %%xmm4\n\t"
		"por	%%xmm4, %%xmm1\n\t"
		"pshufd	$177, %%xmm1, %%xmm0\n\t"
		"movd	%%xmm1, %%eax\n\t"
		"movd	%%xmm0, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (mask3), "m" (expmask), "m" (minuseight), "m" (k1e52), "m" (k02000100));
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square H6.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_H6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, flip_d9;
	UINT64 flipped;

	outflank_v = OUTFLANK_5[((((OL & 0x80808000u) >> 4) + (OH & 0x00808080u)) * 0x00204081u) >> 25]
		& (((((PL & 0x80808080u) >> 4) + (PH & 0x80808080u)) * 0x00204081u) >> 24);
	flipped = FLIPPED_5_V[outflank_v] & 0x0080808080808000;

	outflank_h = OUTFLANK_7[(OH >> 9) & 0x3f] & (PH >> 8);
	flipped |= (UINT64) ((((-outflank_h) & 0x3f) << 9) | ((PH >> 7) & 0x00400000u & OH)) << 32;

	flip_d9 = (OL >> 8) | (OH << 24);
	flip_d9 &= (flip_d9 >> 9) | 0x40000000u;
	flip_d9 &= ((flip_d9 & 0x40200000u) >> 18) | 0x40200000u;
	flipped |= (UINT64) (flip_d9 & -(flip_d9 & (PL << 1))) << 8;

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_H6(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000008080808080, 0x0000004020100804 }};
	static const V2DI mask2 = {{ 0x0080000000000000, 0x0040000000000000 }};
	static const V2DI mask3 = {{ 0x00007f0000000000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i outflank_vd, outflank_h, flipped_v2, flipped_h7g7;
	__m128i PP = set1_by_movd(PL, PH);
	__m128i OO = set1_by_movd(OL, OH);

	outflank_vd = _mm_and_si128(MS1B_epi52(_mm_andnot_si128(OO, mask1.v2)), PP);
	flipped_v2 = _mm_and_si128(_mm_sub_epi64(_mm_setzero_si128(), _mm_add_epi64(outflank_vd, outflank_vd)), mask1.v2);

	flipped_h7g7 = _mm_and_si128(_mm_mulhi_epu16(PP, k02000100.v2), mask2.v2);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_and_si128(flipped_h7g7, OO));

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(OO, mask3.v2)), PP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minusfour.v2), 1));

	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%2, %%xmm4\n\t"		"movd	%3, %%xmm2\n\t"
		"movd	%1, %%xmm3\n\t"		"movd	%4, %%xmm0\n\t"
		"movapd	%10, %%xmm1\n\t"
		"punpckldq %%xmm4, %%xmm3\n\t"	"punpckldq %%xmm0, %%xmm2\n\t"
		"punpcklqdq %%xmm3, %%xmm3\n\t"	"punpcklqdq %%xmm2, %%xmm2\n\t"
		"movdqa	%%xmm2, %%xmm0\n\t"
		"pandn	%5, %%xmm0\n\t"					"movdqa	%11, %%xmm4\n\t"
		"orpd	%%xmm1, %%xmm0\n\t"				"pmulhuw %%xmm3, %%xmm4\n\t"
		"subpd	%%xmm1, %%xmm0\n\t"				"pand	%6, %%xmm4\n\t"
		"andpd	%8, %%xmm0\n\t"
		"addpd	%%xmm1, %%xmm0\n\t"	"movdqa	%%xmm2, %%xmm1\n\t"
						"pandn	%7, %%xmm1\n\t"
		"pand	%%xmm3, %%xmm0\n\t"	"cvtdq2pd %%xmm1, %%xmm1\n\t"
						"andpd	%8, %%xmm1\n\t"
		"paddq	%%xmm0, %%xmm0\n\t"	"cvtpd2dq %%xmm1, %%xmm1\n\t"
						"pand	%%xmm3, %%xmm1\n\t"
		"pxor	%%xmm3, %%xmm3\n\t"	"pmullw	%9, %%xmm1\n\t"
		"psubq	%%xmm0, %%xmm3\n\t"	"psrlq	$1, %%xmm1\n\t"
		"movdqa	%5, %%xmm0\n\t"
		"pand	%%xmm3, %%xmm0\n\t"				"pand	%%xmm2, %%xmm4\n\t"
		"por	%%xmm0, %%xmm1\n\t"				"por	%%xmm4, %%xmm1\n\t"
		"pshufd	$78, %%xmm1, %%xmm4\n\t"
		"por	%%xmm4, %%xmm1\n\t"
		"pshufd	$177, %%xmm1, %%xmm0\n\t"
		"movd	%%xmm1, %%eax\n\t"
		"movd	%%xmm0, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (mask3), "m" (expmask), "m" (minusfour), "m" (k1e52), "m" (k02000100));
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square A7.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_A7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_v, outflank_h, outflank_d7, flippedH, flippedL;

	outflank_v = (((((OL & 0x01010100u) << 4) + (OH & 0x00000101u)) * 0x08040201u + 0x04000000u)
		& (((PL & 0x01010101u) << 4) + (PH & 0x00000001u)) * 0x08040201u) >> 24;
	flippedH = ((outflank_v * 0x00001f0fu) >> 7) & 0x00000101u;
	flippedL = (outflank_v * 0x000e0602u) & 0x01010100u;

	outflank_h = ((OH & 0x007e0000u) + 0x00020000u) & PH;
	flippedH |= (outflank_h - (outflank_h >> 8)) & 0x007e0000u;

	outflank_d7 = (((((OL & 0x08102000u) + (OH & 0x00000204u)) * 0x01010101u) >> 24) + 2)
		& ((((PL & 0x08102040u) + (PH & 0x00000004u)) * 0x01010101u) >> 24);
	flippedH |= ((outflank_d7 * 0x0000f8f0u) >> 8) & 0x00000204u;
	flippedL |= (outflank_d7 * 0x00e0c080u) & 0x08102000u;

	return ULL(flippedH, flippedL);
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_A7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000010101010101, 0x0000020408102040 }};
	UINT64 flipped;

	FLIP_MS1B_AB78(49);

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square B7.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_B7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_v, outflank_h, outflank_d7, flippedH, flippedL;

	outflank_v = (((((OL & 0x02020200u) << 3) + ((OH & 0x00000202u) >> 1)) * 0x08040201u + 0x04000000u)
		& (((PL & 0x02020202u) << 3) + ((PH & 0x00000002u) >> 1)) * 0x08040201u) >> 24;
	flippedH = ((outflank_v * 0x00001f0fu) >> 6) & 0x00000202u;
	flippedL = (outflank_v * 0x001c0c04u) & 0x02020200u;

	outflank_h = ((OH & 0x007c0000u) + 0x00040000u) & PH;
	flippedH |= (outflank_h - (outflank_h >> 8)) & 0x007c0000u;

	outflank_d7 = ((((OL & 0x10204000u) + (OH & 0x00000408u)) * 0x01010101u + 0x04000000u)
		& ((PL & 0x10204080u) + (PH & 0x00000008u)) * 0x01010101u) >> 25;
	flippedH |= ((outflank_d7 * 0x0000f8f0u) >> 7) & 0x00000408u;
	flippedL |= (outflank_d7 * 0x01c18100u) & 0x10204000u;

	return ULL(flippedH, flippedL);
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_B7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000020202020202, 0x0000040810204080 }};
	UINT64 flipped;

	FLIP_MS1B_AB78(50);

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square C7.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_C7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d;
	UINT64 flipped;

	outflank_v = (((((OL & 0x04040400u) << 2) + ((OH & 0x00000404u) >> 2)) * 0x08040201u + 0x04000000u)
		& (((PL & 0x04040404u) << 2) + ((PH & 0x00000004u) >> 2)) * 0x08040201u) >> 24;
	flipped = ULL(((outflank_v * 0x00001f0fu) >> 5) & 0x00000404u, (outflank_v * 0x00381808u) & 0x04040400u);

	outflank_h = OUTFLANK_2[(OH >> 17) & 0x3f] & (PH >> 16);
	flipped |= FLIPPED_2_H[outflank_h] & 0x00ff000000000000;

	outflank_d = OUTFLANK_2[(((OH & 0x00040a10u) + (OL & 0x20400000u)) * 0x01010101u) >> 25]
		& ((((PH & 0x00040a11u) + (PL & 0x20408000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_2_H[outflank_d] & 0x00040a1020400000;	// A5C7H2

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_C7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000040404040404, 0x0000081020408000 }};
	UINT64 flipped;
	unsigned int outflank_h, FH;

	FLIP_MS1B_2_VEC;

	outflank_h = OUTFLANK_2[(OH >> 17) & 0x3f] & (PH >> 16);
	FH = ((unsigned char) FLIPPED_2_H[outflank_h] << 16)
		| (OH & (PH << 9) & 0x00000200u);
	return flipped | ((UINT64) FH << 32);
}
#endif

/**
 * Compute flipped discs when playing on square D7.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_D7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d;
	UINT64 flipped;

	outflank_v = (((((OL & 0x08080800u) << 1) + ((OH & 0x00000808u) >> 3)) * 0x08040201u + 0x04000000u)
		& (((PL & 0x08080808u) << 1) + ((PH & 0x00000008u) >> 3)) * 0x08040201u) >> 24;
	flipped = ULL(((outflank_v * 0x00001f0fu) >> 4) & 0x00000808u, (outflank_v * 0x00703010u) & 0x08080800u);

	outflank_h = OUTFLANK_3[(OH >> 17) & 0x3f] & (PH >> 16);
	flipped |= FLIPPED_3_H[outflank_h] & 0x00ff000000000000;

	outflank_d = OUTFLANK_3[(((OH & 0x00081422u) + (OL & 0x40000000u)) * 0x01010101u) >> 25]
		& ((((PH & 0x00081422u) + (PL & 0x41800000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_3_H[outflank_d] & 0x0008142240000000;	// A4D7H3

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_D7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000080808080808, 0x0008142241800000 }};	// A4D7H3
	UINT64 flipped;
	unsigned int outflank_h;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, index_d;
	unsigned int outflank_v, outflank_d, index_v;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 4));
	outflank_v = (OUTFLANK_7[(index_v >> 8) & 0x3e] >> 1) & index_v;

	index_d = _mm_sad_epu8(_mm_and_si128(OP, _mm_shuffle_epi32(mask1.v2, DUPHI)), _mm_setzero_si128());
	outflank_d = OUTFLANK_3[(_mm_extract_epi16(index_d, 4) >> 1) & 0x3f] & _mm_cvtsi128_si32(index_d);

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_7_V[outflank_v], &FLIPPED_3_H[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$4, %%xmm0\n\t"				"pxor	%%xmm2, %%xmm2\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"psadbw %%xmm2, %%xmm1\n\t"
								"pextrw	$4, %%xmm1, %%ebx\n\t"
		"movzx	%%dh, %%ecx\n\t"			"shrl	$1, %%ebx\n\t"
		"andl	$62, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_7(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
		"shrl	$1, %%ecx\n\t"				"movd	%%xmm1, %%eax\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_7_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_3_H(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = OUTFLANK_3[(OH >> 17) & 0x3f] & (PH >> 16);
	return flipped | (FLIPPED_3_H[outflank_h] & 0x00ff000000000000);
}
#endif

/**
 * Compute flipped discs when playing on square E7.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_E7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d;
	UINT64 flipped;

	outflank_v = ((((OL & 0x10101000u) + ((OH & 0x00001010u) >> 4)) * 0x08040201u + 0x04000000u)
		& ((PL & 0x10101010u) + ((PH & 0x00000010u) >> 4)) * 0x08040201u) >> 24;
	flipped = ULL(((outflank_v * 0x00001f0fu) >> 3) & 0x00001010u, (outflank_v * 0x00e06020u) & 0x10101000u);

	outflank_h = OUTFLANK_4[(OH >> 17) & 0x3f] & (PH >> 16);
	flipped |= FLIPPED_4_H[outflank_h] & 0x00ff000000000000;

	outflank_d = OUTFLANK_4[(((OH & 0x00102844u) + (OL & 0x02000000u)) * 0x01010101u) >> 25]
		& ((((PH & 0x00102844u) + (PL & 0x82010000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_4_H[outflank_d] & 0x0010284402000000;	// A3E7H4

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_E7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000101010101010, 0x0010284482010000 }};	// A3E7H4
	UINT64 flipped;
	unsigned int outflank_h;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, index_d;
	unsigned int outflank_v, outflank_d, index_v;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 3));
	outflank_v = (OUTFLANK_7[(index_v >> 8) & 0x3e] >> 1) & index_v;

	index_d = _mm_sad_epu8(_mm_and_si128(OP, _mm_shuffle_epi32(mask1.v2, DUPHI)), _mm_setzero_si128());
	outflank_d = OUTFLANK_4[(_mm_extract_epi16(index_d, 4) >> 1) & 0x3f] & _mm_cvtsi128_si32(index_d);

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_7_V[outflank_v], &FLIPPED_4_H[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$3, %%xmm0\n\t"				"pxor	%%xmm2, %%xmm2\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"psadbw %%xmm2, %%xmm1\n\t"
								"pextrw	$4, %%xmm1, %%ebx\n\t"
		"movzx	%%dh, %%ecx\n\t"			"shrl	$1, %%ebx\n\t"
		"andl	$62, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_7(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
		"shrl	$1, %%ecx\n\t"				"movd	%%xmm1, %%eax\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_7_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_4_H(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = OUTFLANK_4[(OH >> 17) & 0x3f] & (PH >> 16);
	return flipped | (FLIPPED_4_H[outflank_h] & 0x00ff000000000000);
}
#endif

/**
 * Compute flipped discs when playing on square F7.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_F7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d;
	UINT64 flipped;

	outflank_v = (((((OL & 0x20202000u) >> 1) + ((OH & 0x00002020u) >> 5)) * 0x08040201u + 0x04000000u)
		& (((PL & 0x20202020u) >> 1) + ((PH & 0x00000020u) >> 5)) * 0x08040201u) >> 24;
	flipped = ULL(((outflank_v * 0x00001f0fu) >> 2) & 0x00002020u, (outflank_v * 0x01c0c040u) & 0x20202000u);

	outflank_h = OUTFLANK_5[(OH >> 17) & 0x3f] & (PH >> 16);
	flipped |= FLIPPED_5_H[outflank_h] & 0x00ff000000000000;

	outflank_d = OUTFLANK_5[(((OH & 0x00205008u) + (OL & 0x04020000u)) * 0x01010101u) >> 25]
		& ((((PH & 0x00205088u) + (PL & 0x04020100u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_5_H[outflank_d] & 0x0020500804020000;	// A2F7H5

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_F7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000202020202020, 0x0000100804020100 }};
	UINT64 flipped;
	unsigned int outflank_h, FH;

	FLIP_MS1B_2_VEC;

	outflank_h = OUTFLANK_5[(OH >> 17) & 0x3f] & (PH >> 16);
	FH = ((unsigned char) FLIPPED_5_H[outflank_h] << 16)
		| (OH & (PH << 7) & 0x00004000u);
	return flipped | ((UINT64) FH << 32);
}
#endif

/**
 * Compute flipped discs when playing on square G7.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_G7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d9, flippedH, flippedL;

	outflank_v = (((((OL & 0x40404000u) >> 2) + ((OH & 0x00004040u) >> 6)) * 0x08040201u + 0x04000000u)
		& (((PL & 0x40404040u) >> 2) + ((PH & 0x00000040u) >> 6)) * 0x08040201u) >> 24;
	flippedH = ((outflank_v * 0x00001f0fu) >> 1) & 0x00004040u;
	flippedL = (outflank_v * 0x03818080u) & 0x40404000u;

	outflank_h = OUTFLANK_7[(OH >> 16) & 0x3e] & (PH >> 15);
	flippedH |= ((-outflank_h) & 0x3e) << 16;

	outflank_d9 = OUTFLANK_7[(((OL & 0x08040200u) + (OH & 0x00002010u)) * 0x01010101u) >> 24]
		& ((((PL & 0x08040201u) + (PH & 0x00000010u)) * 0x01010101u) >> 23);
	flippedH |= (outflank_d9 * 0x00001f0fu) & 0x00002010u;
	flippedL |= (outflank_d9 * 0x07030100u) & 0x08040200u;

	return ULL(flippedH, flippedL);
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_G7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000404040404040, 0x0000201008040201 }};
	static const V2DI mask2 = {{ 0x003f000000000000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i outflank_vd, outflank_h, flipped_v2;
	__m128i PP = set1_by_movd(PL, PH);
	__m128i OO = set1_by_movd(OL, OH);

	outflank_vd = _mm_and_si128(MS1B_epi52(_mm_andnot_si128(OO, mask1.v2)), PP);
	flipped_v2 = _mm_and_si128(_mm_sub_epi64(_mm_setzero_si128(), _mm_add_epi64(outflank_vd, outflank_vd)), mask1.v2);

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(OO, mask2.v2)), PP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minus0800.v2), 10));

	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%2, %%xmm0\n\t"		"movd	%3, %%xmm2\n\t"
		"movd	%1, %%xmm1\n\t"		"movd	%4, %%xmm3\n\t"
		"punpckldq %%xmm0, %%xmm1\n\t"	"punpckldq %%xmm3, %%xmm2\n\t"
		"punpcklqdq %%xmm1, %%xmm1\n\t"	"punpcklqdq %%xmm2, %%xmm2\n\t"
		"movapd	%9, %%xmm3\n\t"		"movdqa	%%xmm2, %%xmm0\n\t"
		"pandn	%5, %%xmm0\n\t"		"pandn	%6, %%xmm2\n\t"
		"orpd	%%xmm3, %%xmm0\n\t"
		"subpd	%%xmm3, %%xmm0\n\t"	"cvtdq2pd %%xmm2, %%xmm2\n\t"
		"andpd	%7, %%xmm0\n\t"		"andpd	%7, %%xmm2\n\t"
		"addpd	%%xmm3, %%xmm0\n\t"	"cvtpd2dq %%xmm2, %%xmm2\n\t"
		"pand	%%xmm1, %%xmm0\n\t"
		"pxor	%%xmm3, %%xmm3\n\t"
		"paddq	%%xmm0, %%xmm0\n\t"
		"psubq	%%xmm0, %%xmm3\n\t"	"pand	%%xmm2, %%xmm1\n\t"
		"movdqa	%5, %%xmm0\n\t"		"pmullw	%8, %%xmm1\n\t"
		"pand	%%xmm3, %%xmm0\n\t"	"psrlw	$10, %%xmm1\n\t"
		"por	%%xmm0, %%xmm1\n\t"
		"pshufd	$78, %%xmm1, %%xmm0\n\t"
		"por	%%xmm0, %%xmm1\n\t"
		"pshufd	$177, %%xmm1, %%xmm0\n\t"
		"movd	%%xmm1, %%eax\n\t"
		"movd	%%xmm0, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (expmask), "m" (minus0800), "m" (k1e52));
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square H7.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_H7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d9, flippedH, flippedL;

	outflank_v = (((((OL & 0x80808000u) >> 3) + ((OH & 0x00008080u) >> 7)) * 0x08040201u + 0x04000000u)
		& (((PL & 0x80808080u) >> 3) + ((PH & 0x00000080u) >> 7)) * 0x08040201u) >> 24;
	flippedH = (outflank_v * 0x00001f0fu) & 0x00008080u;
	flippedL = (outflank_v * 0x07030100u) & 0x80808000u;

	outflank_h = OUTFLANK_7[(OH >> 17) & 0x3f] & (PH >> 16);
	flippedH |= ((-outflank_h) & 0x3f) << 17;

	outflank_d9 = OUTFLANK_7[(((OL & 0x10080400u) + (OH & 0x00004020u)) * 0x01010101u) >> 25]
		& ((((PL & 0x10080402u) + (PH & 0x00000020u)) * 0x01010101u) >> 24);
	flippedH |= (outflank_d9 * 0x00003e1eu) & 0x00004020u;
	flippedL |= (outflank_d9 * 0x0e060200u) & 0x10080400u;

	return ULL(flippedH, flippedL);
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_H7(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0000808080808080, 0x0000402010080402 }};
	static const V2DI mask2 = {{ 0x007f000000000000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i outflank_vd, outflank_h, flipped_v2;
	__m128i PP = set1_by_movd(PL, PH);
	__m128i OO = set1_by_movd(OL, OH);

	outflank_vd = _mm_and_si128(MS1B_epi52(_mm_andnot_si128(OO, mask1.v2)), PP);
	flipped_v2 = _mm_and_si128(_mm_sub_epi64(_mm_setzero_si128(), _mm_add_epi64(outflank_vd, outflank_vd)), mask1.v2);

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(OO, mask2.v2)), PP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minus0400.v2), 9));

	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%2, %%xmm0\n\t"		"movd	%3, %%xmm2\n\t"
		"movd	%1, %%xmm1\n\t"		"movd	%4, %%xmm3\n\t"
		"punpckldq %%xmm0, %%xmm1\n\t"	"punpckldq %%xmm3, %%xmm2\n\t"
		"punpcklqdq %%xmm1, %%xmm1\n\t"	"punpcklqdq %%xmm2, %%xmm2\n\t"
		"movapd	%9, %%xmm3\n\t"		"movdqa	%%xmm2, %%xmm0\n\t"
		"pandn	%5, %%xmm0\n\t"		"pandn	%6, %%xmm2\n\t"
		"orpd	%%xmm3, %%xmm0\n\t"
		"subpd	%%xmm3, %%xmm0\n\t"	"cvtdq2pd %%xmm2, %%xmm2\n\t"
		"andpd	%7, %%xmm0\n\t"		"andpd	%7, %%xmm2\n\t"
		"addpd	%%xmm3, %%xmm0\n\t"	"cvtpd2dq %%xmm2, %%xmm2\n\t"
		"pand	%%xmm1, %%xmm0\n\t"
		"pxor	%%xmm3, %%xmm3\n\t"
		"paddq	%%xmm0, %%xmm0\n\t"
		"psubq	%%xmm0, %%xmm3\n\t"	"pand	%%xmm2, %%xmm1\n\t"
		"movdqa	%5, %%xmm0\n\t"		"pmullw	%8, %%xmm1\n\t"
		"pand	%%xmm3, %%xmm0\n\t"	"psrlw	$9, %%xmm1\n\t"
		"por	%%xmm0, %%xmm1\n\t"
		"pshufd	$78, %%xmm1, %%xmm0\n\t"
		"por	%%xmm0, %%xmm1\n\t"
		"pshufd	$177, %%xmm1, %%xmm0\n\t"
		"movd	%%xmm1, %%eax\n\t"
		"movd	%%xmm0, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (expmask), "m" (minus0400), "m" (k1e52));
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square A8.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_A8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_v, outflank_h, outflank_d7, flippedH, flippedL;

	outflank_v = (((((OL & 0x01010100u) << 4) + (OH & 0x00010101u)) * 0x08040201u + 0x02000000u)
		& (((PL & 0x01010101u) << 4) + (PH & 0x00000101u)) * 0x08040201u) >> 24;
	flippedH = ((outflank_v * 0x003f1f0fu) >> 7) & 0x00010101u;
	flippedL = (outflank_v * 0x000e0602u) & 0x01010100u;

	outflank_h = (OH + 0x02000000u) & PH;
	flippedH |= (outflank_h - (outflank_h >> 8)) & 0x7e000000u;

	outflank_d7 = ((((OL & 0x10204000u) + (OH & 0x00020408u)) * 0x01010101u + 0x02000000u)
		& ((PL & 0x10204080u) + (PH & 0x00000408u)) * 0x01010101u) >> 24;
	flippedH |= ((outflank_d7 * 0x00fcf8f0u) >> 8) & 0x00020408u;
	flippedL |= (outflank_d7 * 0x00e0c080u) & 0x10204000u;

	return ULL(flippedH, flippedL);
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_A8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0001010101010101, 0x0002040810204080 }};
	UINT64 flipped;

	FLIP_MS1B_AB78(57);

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square B8.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_B8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_v, outflank_h, outflank_d7, flippedH, flippedL;

	outflank_v = (((((OL & 0x02020200u) << 3) + ((OH & 0x00020202u) >> 1)) * 0x08040201u + 0x02000000u)
		& (((PL & 0x02020202u) << 3) + ((PH & 0x00000202u) >> 1)) * 0x08040201u) >> 24;
	flippedH = ((outflank_v * 0x003f1f0fu) >> 6) & 0x00020202u;
	flippedL = (outflank_v * 0x001c0c04u) & 0x02020200u;

	outflank_h = (OH + 0x04000000u) & PH;
	flippedH |= (outflank_h - (outflank_h >> 8)) & 0x7c000000u;

	outflank_d7 = ((((OL & 0x20400000u) + (OH & 0x00040810u)) * 0x01010101u + 0x04000000u)
		& ((PL & 0x20408000u) + (PH & 0x00000810u)) * 0x01010101u) >> 25;
	flippedH |= ((outflank_d7 * 0x00fcf8f0u) >> 7) & 0x00040810u;
	flippedL |= (outflank_d7 * 0x01c18000u) & 0x20400000u;

	return ULL(flippedH, flippedL);
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_B8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0002020202020202, 0x0004081020408000 }};
	UINT64 flipped;

	FLIP_MS1B_AB78(58);

	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square C8.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_C8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d;
	UINT64 flipped;

	outflank_v = (((((OL & 0x04040400u) << 2) + ((OH & 0x00040404u) >> 2)) * 0x08040201u + 0x02000000u)
		& (((PL & 0x04040404u) << 2) + ((PH & 0x00000404u) >> 2)) * 0x08040201u) >> 24;
	flipped = ULL(((outflank_v * 0x003f1f0fu) >> 5) & 0x00040404u, (outflank_v * 0x00381808u) & 0x04040400u);

	outflank_h = OUTFLANK_2[(OH >> 25) & 0x3f] & (PH >> 24);
	flipped |= FLIPPED_2_H[outflank_h] & 0xff00000000000000;

	outflank_d = OUTFLANK_2[(((OH & 0x040a1020u) + (OL & 0x40000000u)) * 0x01010101u) >> 25]
		& ((((PH & 0x040a1120u) + (PL & 0x40800000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_2_H[outflank_d] & 0x040a102040000000;	// A6C8H3

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_C8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0004040404040404, 0x0008102040800000 }};
	UINT64 flipped;
	unsigned int outflank_h, FH;

	FLIP_MS1B_2_VEC;

	outflank_h = OUTFLANK_2[(OH >> 25) & 0x3f] & (PH >> 24);
	FH = ((unsigned char) FLIPPED_2_H[outflank_h] << 24)
		| (OH & (PH << 9) & 0x00020000u);
	return flipped | ((UINT64) FH << 32);
}
#endif

/**
 * Compute flipped discs when playing on square D8.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_D8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d;
	UINT64 flipped;

	outflank_v = (((((OL & 0x08080800u) << 1) + ((OH & 0x00080808u) >> 3)) * 0x08040201u + 0x02000000u)
		& (((PL & 0x08080808u) << 1) + ((PH & 0x00000808u) >> 3)) * 0x08040201u) >> 24;
	flipped = ULL(((outflank_v * 0x003f1f0fu) >> 4) & 0x00080808u, (outflank_v * 0x00703010u) & 0x08080800u);

	outflank_h = OUTFLANK_3[(OH >> 25) & 0x3f] & (PH >> 24);
	flipped |= FLIPPED_3_H[outflank_h] & 0xff00000000000000;

	outflank_d = OUTFLANK_3[((OH & 0x08142240u) * 0x01010101u) >> 25]
		& ((((PH & 0x08142241u) + (PL & 0x80000000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_3_H[outflank_d] & 0x0814224000000000;	// A5D8H4

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_D8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0008080808080808, 0x0814224180000000 }};	// A5D8H4
	UINT64 flipped;
	unsigned int outflank_h;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, index_d;
	unsigned int outflank_v, outflank_d, index_v;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 4));
	outflank_v = OUTFLANK_7[(index_v >> 9) & 0x3f] & index_v;

	index_d = _mm_sad_epu8(_mm_and_si128(OP, _mm_shuffle_epi32(mask1.v2, DUPHI)), _mm_setzero_si128());
	outflank_d = OUTFLANK_3[(_mm_extract_epi16(index_d, 4) >> 1) & 0x3f] & _mm_cvtsi128_si32(index_d);

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_7_V[outflank_v], &FLIPPED_3_H[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$4, %%xmm0\n\t"				"pxor	%%xmm2, %%xmm2\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"psadbw %%xmm2, %%xmm1\n\t"
		"movl	%%edx, %%ecx\n\t"			"pextrw	$4, %%xmm1, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$1, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_7(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_3(%%ebx), %%ebx\n\t"
								"movd	%%xmm1, %%eax\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_7_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_3_H(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = OUTFLANK_3[(OH >> 25) & 0x3f] & (PH >> 24);
	return flipped | (FLIPPED_3_H[outflank_h] & 0xff00000000000000);
}
#endif

/**
 * Compute flipped discs when playing on square E8.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_E8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d;
	UINT64 flipped;

	outflank_v = ((((OL & 0x10101000u) + ((OH & 0x00101010u) >> 4)) * 0x08040201u + 0x02000000u)
		& ((PL & 0x10101010u) + ((PH & 0x00001010u) >> 4)) * 0x08040201u) >> 24;
	flipped = ULL(((outflank_v * 0x003f1f0fu) >> 3) & 0x00101010u, (outflank_v * 0x00e06020u) & 0x10101000u);

	outflank_h = OUTFLANK_4[(OH >> 25) & 0x3f] & (PH >> 24);
	flipped |= FLIPPED_4_H[outflank_h] & 0xff00000000000000;

	outflank_d = OUTFLANK_4[((OH & 0x10284402u) * 0x01010101u) >> 25]
		& ((((PH & 0x10284482u) + (PL & 0x01000000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_4_H[outflank_d] & 0x1028440200000000;	// A4E8H5

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_E8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0010101010101010, 0x1028448201000000 }};	// A4E8H5
	UINT64 flipped;
	unsigned int outflank_h;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i OP = _mm_set_epi32(OH, OL, PH, PL);
	__m128i	flipped_v2, index_d;
	unsigned int outflank_v, outflank_d, index_v;

	index_v = _mm_movemask_epi8(_mm_slli_epi64(OP, 3));
	outflank_v = OUTFLANK_7[(index_v >> 9) & 0x3f] & index_v;

	index_d = _mm_sad_epu8(_mm_and_si128(OP, _mm_shuffle_epi32(mask1.v2, DUPHI)), _mm_setzero_si128());
	outflank_d = OUTFLANK_4[(_mm_extract_epi16(index_d, 4) >> 1) & 0x3f] & _mm_cvtsi128_si32(index_d);

	flipped_v2 = _mm_and_si128(load64x2(&FLIPPED_7_V[outflank_v], &FLIPPED_4_H[outflank_d]), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"punpcklqdq %%xmm0, %%xmm1\n\t"			"pshufd	$238, %5, %%xmm2\n\t"
		"movdqa	%%xmm1, %%xmm0\n\t"			"pand	%%xmm2, %%xmm1\n\t"
		"psllq	$3, %%xmm0\n\t"				"pxor	%%xmm2, %%xmm2\n\t"
		"pmovmskb %%xmm0, %%edx\n\t"			"psadbw %%xmm2, %%xmm1\n\t"
		"movl	%%edx, %%ecx\n\t"			"pextrw	$4, %%xmm1, %%ebx\n\t"
		"shrl	$9, %%ecx\n\t"				"shrl	$1, %%ebx\n\t"
		"andl	$63, %%ecx\n\t"				"andl	$63, %%ebx\n\t"
		"movzbl	"_"OUTFLANK_7(%%ecx), %%ecx\n\t"	"movzbl	"_"OUTFLANK_4(%%ebx), %%ebx\n\t"
								"movd	%%xmm1, %%eax\n\t"
		"andl	%%ecx, %%edx\n\t"			"andl	%%ebx, %%eax\n\t"
		"movq	"_"FLIPPED_7_V(,%%edx,8), %%xmm0\n\t"	"movhps	"_"FLIPPED_4_H(,%%eax,8), %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1)
	: "ebx", "ecx");
#endif

	outflank_h = OUTFLANK_4[(OH >> 25) & 0x3f] & (PH >> 24);
	return flipped | (FLIPPED_4_H[outflank_h] & 0xff00000000000000);
}
#endif

/**
 * Compute flipped discs when playing on square F8.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_F8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d;
	UINT64 flipped;

	outflank_v = (((((OL & 0x20202000u) >> 1) + ((OH & 0x00202020u) >> 5)) * 0x08040201u + 0x02000000u)
		& (((PL & 0x20202020u) >> 1) + ((PH & 0x00002020u) >> 5)) * 0x08040201u) >> 24;
	flipped = ULL(((outflank_v * 0x003f1f0fu) >> 2) & 0x00202020u, (outflank_v * 0x01c0c040u) & 0x20202000u);

	outflank_h = OUTFLANK_5[(OH >> 25) & 0x3f] & (PH >> 24);
	flipped |= FLIPPED_5_H[outflank_h] & 0xff00000000000000;

	outflank_d = OUTFLANK_5[(((OH & 0x20500804u) + (OL & 0x02000000u)) * 0x01010101u) >> 25]
		& ((((PH & 0x20508804u) + (PL & 0x02010000u)) * 0x01010101u) >> 24);
	flipped |= FLIPPED_5_H[outflank_d] & 0x2050080402000000;	// A3F8H6

	return flipped;
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_F8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0020202020202020, 0x0010080402010000 }};
	UINT64 flipped;
	unsigned int outflank_h, FH;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i PP = set1_by_movd(PL, PH);
	__m128i OO = set1_by_movd(OL, OH);
	__m128i	outflank_vd, flipped_vd;

	outflank_vd = _mm_and_si128(_mm_slli_epi64(MS1B_epi52(_mm_srli_epi64(_mm_andnot_si128(OO, mask1.v2), 4)), 4), PP);
	flipped_vd = _mm_and_si128(_mm_sub_epi64(_mm_setzero_si128(), _mm_add_epi64(outflank_vd, outflank_vd)), mask1.v2);
	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_vd, _mm_shuffle_epi32(flipped_vd, SWAP64)));

#else
	__asm__(
		"movd	%2, %%xmm3\n\t"				"movd	%4, %%xmm2\n\t"
		"movd	%1, %%xmm1\n\t"				"movd	%3, %%xmm0\n\t"
		"punpckldq %%xmm3, %%xmm1\n\t"			"punpckldq %%xmm2, %%xmm0\n\t"
		"movapd	%6, %%xmm2\n\t"
		"punpcklqdq %%xmm1, %%xmm1\n\t"			"punpcklqdq %%xmm0, %%xmm0\n\t"
		"pandn	%5, %%xmm0\n\t"
		"psrlq	$4, %%xmm0\n\t"
		"orpd	%%xmm2, %%xmm0\n\t"
		"subpd	%%xmm2, %%xmm0\n\t"
		"andpd	%7, %%xmm0\n\t"
		"addpd	%%xmm2, %%xmm0\n\t"
		"psllq	$4, %%xmm0\n\t"
		"pand	%%xmm0, %%xmm1\n\t"
		"pxor	%%xmm0, %%xmm0\n\t"
		"paddq	%%xmm1, %%xmm1\n\t"
		"psubq	%%xmm1, %%xmm0\n\t"
		"pand	%5, %%xmm0\n\t"
		"pshufd	$78, %%xmm0, %%xmm1\n\t"
		"por	%%xmm1, %%xmm0\n\t"
		"pshufd	$177, %%xmm0, %%xmm1\n\t"
		"movd	%%xmm0, %%eax\n\t"
		"movd	%%xmm1, %%edx\n\t"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (k1e52), "m" (expmask));
#endif

	outflank_h = OUTFLANK_5[(OH >> 25) & 0x3f] & (PH >> 24);
	FH = ((unsigned char) FLIPPED_5_H[outflank_h] << 24)
		| (OH & (PH << 7) & 0x00400000u);
	return flipped | ((UINT64) FH << 32);
}
#endif

/**
 * Compute flipped discs when playing on square G8.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_G8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d9, flippedH, flippedL;

	outflank_v = (((((OL & 0x40404000u) >> 2) + ((OH & 0x00404040u) >> 6)) * 0x08040201u + 0x02000000u)
		& (((PL & 0x40404040u) >> 2) + ((PH & 0x00004040u) >> 6)) * 0x08040201u) >> 24;
	flippedH = ((outflank_v * 0x003f1f0fu) >> 1) & 0x00404040u;
	flippedL = (outflank_v * 0x03818080u) & 0x40404000u;

	outflank_h = OUTFLANK_7[(OH >> 24) & 0x3e] & (PH >> 23);
	flippedH |= ((-outflank_h) & 0x3e) << 24;

	outflank_d9 = OUTFLANK_7[(((OL & 0x04020000u) + (OH & 0x00201008u)) * 0x01010101u) >> 24]
		& ((((PL & 0x04020100u) + (PH & 0x00001008u)) * 0x01010101u) >> 23);
	flippedH |= (outflank_d9 * 0x001f0f07u) & 0x00201008u;
	flippedL |= (outflank_d9 * 0x03010000u) & 0x04020000u;

	return ULL(flippedH, flippedL);
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_G8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0040404040404040, 0x0020100804020100 }};
	static const V2DI mask2 = {{ 0x3f00000000000000, 0 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i outflank_vd, outflank_h, flipped_v2;
	__m128i PP = set1_by_movd(PL, PH);
	__m128i OO = set1_by_movd(OL, OH);

	outflank_vd = _mm_and_si128(_mm_slli_epi64(MS1B_epi52(_mm_srli_epi64(_mm_andnot_si128(OO, mask1.v2), 4)), 4), PP);
	flipped_v2 = _mm_and_si128(_mm_sub_epi64(_mm_setzero_si128(), _mm_add_epi64(outflank_vd, outflank_vd)), mask1.v2);

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(OO, mask2.v2)), PP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minuseight.v2), 2));

	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));
#else
	__asm__(
		"movd	%2, %%xmm0\n\t"		"movd	%3, %%xmm2\n\t"
		"movd	%1, %%xmm1\n\t"		"movd	%4, %%xmm3\n\t"
		"punpckldq %%xmm0, %%xmm1\n\t"	"punpckldq %%xmm3, %%xmm2\n\t"
		"punpcklqdq %%xmm1, %%xmm1\n\t"	"punpcklqdq %%xmm2, %%xmm2\n\t"
		"movapd	%9, %%xmm3\n\t"		"movdqa	%%xmm2, %%xmm0\n\t"
		"pandn	%5, %%xmm0\n\t"		"pandn	%6, %%xmm2\n\t"
		"psrlq	$4, %%xmm0\n\t"
		"orpd	%%xmm3, %%xmm0\n\t"
		"subpd	%%xmm3, %%xmm0\n\t"	"cvtdq2pd %%xmm2, %%xmm2\n\t"
		"andpd	%7, %%xmm0\n\t"		"andpd	%7, %%xmm2\n\t"
		"addpd	%%xmm3, %%xmm0\n\t"	"cvtpd2dq %%xmm2, %%xmm2\n\t"
		"psllq	$4, %%xmm0\n\t"
		"pand	%%xmm1, %%xmm0\n\t"
		"pxor	%%xmm3, %%xmm3\n\t"
		"paddq	%%xmm0, %%xmm0\n\t"
		"psubq	%%xmm0, %%xmm3\n\t"	"pand	%%xmm2, %%xmm1\n\t"
		"movdqa	%5, %%xmm0\n\t"		"pmullw	%8, %%xmm1\n\t"
		"pand	%%xmm3, %%xmm0\n\t"	"psrlw	$2, %%xmm1\n\t"
		"por	%%xmm0, %%xmm1\n\t"
		"pshufd	$78, %%xmm1, %%xmm0\n\t"
		"por	%%xmm0, %%xmm1\n\t"
		"pshufd	$177, %%xmm1, %%xmm0\n\t"
		"movd	%%xmm1, %%eax\n\t"
		"movd	%%xmm0, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (expmask), "m" (minuseight), "m" (k1e52));
#endif
	return flipped;
}
#endif

/**
 * Compute flipped discs when playing on square H8.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
#ifndef hasSSE2
static UINT64 flip_H8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	unsigned int outflank_h, outflank_v, outflank_d9, flippedH, flippedL;

	outflank_v = (((((OL & 0x80808000u) >> 3) + ((OH & 0x00808080u) >> 7)) * 0x08040201u + 0x02000000u)
		& (((PL & 0x80808080u) >> 3) + ((PH & 0x00008080u) >> 7)) * 0x08040201u) >> 24;
	flippedH = (outflank_v * 0x003f1f0fu) & 0x00808080u;
	flippedL = (outflank_v * 0x07030100u) & 0x80808000u;

	outflank_h = OUTFLANK_7[(OH >> 25) & 0x3f] & (PH >> 24);
	flippedH |= ((-outflank_h) & 0x3f) << 25;

	outflank_d9 = OUTFLANK_7[(((OL & 0x08040200u) + (OH & 0x00402010u)) * 0x01010101u) >> 25]
		& ((((PL & 0x08040201u) + (PH & 0x00002010u)) * 0x01010101u) >> 24);
	flippedH |= (outflank_d9 * 0x007e3e1eu) & 0x00402010u;
	flippedL |= (outflank_d9 * 0x0e060200u) & 0x08040200u;

	return ULL(flippedH, flippedL);
}
#endif
#if defined(hasSSE2) || defined(USE_GAS_MMX) || defined(USE_MSVC_X86)
static UINT64 flip_sse_H8(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	static const V2DI mask1 = {{ 0x0080808080808080, 0x0040201008040201 }};
	static const V2DI mask2 = {{ 0x7f00000000000000, 0 }};
	static const V2DI mulk1 = {{ 0x0001000100010001, 0x0001000100100010 }};
	static const V2DI mulk2 = {{ 0x0010001000100010, 0x0010001000010001 }};
	UINT64 flipped;
#if defined(hasSSE2) || defined (USE_MSVC_X86)
	__m128i	outflank_vd, outflank_h, flipped_v2;
	__m128i PP = set1_by_movd(PL, PH);
	__m128i OO = set1_by_movd(OL, OH);

	outflank_vd = _mm_srli_epi64(_mm_mullo_epi16(_mm_andnot_si128(OO, mask1.v2), mulk1.v2), 4);
	outflank_vd = _mm_and_si128(_mm_mullo_epi16(MS1B_epi52(outflank_vd), mulk2.v2), PP);
	flipped_v2 = _mm_and_si128(_mm_sub_epi64(_mm_setzero_si128(), _mm_add_epi64(outflank_vd, outflank_vd)), mask1.v2);

	outflank_h = _mm_and_si128(MS1B_epi32(_mm_andnot_si128(OO, mask2.v2)), PP);
	flipped_v2 = _mm_or_si128(flipped_v2, _mm_srli_epi16(_mm_mullo_epi16(outflank_h, minusfour.v2), 1));

	flipped = _mm_cvtsi128_si64(_mm_or_si128(flipped_v2, _mm_shuffle_epi32(flipped_v2, SWAP64)));

#else
	__asm__(
		"movd	%2, %%xmm0\n\t"		"movd	%3, %%xmm2\n\t"
		"movd	%1, %%xmm1\n\t"		"movd	%4, %%xmm3\n\t"
		"punpckldq %%xmm0, %%xmm1\n\t"	"punpckldq %%xmm3, %%xmm2\n\t"
		"punpcklqdq %%xmm1, %%xmm1\n\t"	"punpcklqdq %%xmm2, %%xmm2\n\t"
		"movapd	%9, %%xmm3\n\t"		"movdqa	%%xmm2, %%xmm0\n\t"
		"pandn	%5, %%xmm0\n\t"		"pandn	%6, %%xmm2\n\t"
		"pmullw	%10, %%xmm0\n\t"
		"psrlq	$4, %%xmm0\n\t"
		"orpd	%%xmm3, %%xmm0\n\t"
		"subpd	%%xmm3, %%xmm0\n\t"	"cvtdq2pd %%xmm2, %%xmm2\n\t"
		"andpd	%7, %%xmm0\n\t"		"andpd	%7, %%xmm2\n\t"
		"addpd	%%xmm3, %%xmm0\n\t"	"cvtpd2dq %%xmm2, %%xmm2\n\t"
		"pmullw	%11, %%xmm0\n\t"
		"pand	%%xmm1, %%xmm0\n\t"
		"pxor	%%xmm3, %%xmm3\n\t"
		"paddq	%%xmm0, %%xmm0\n\t"
		"psubq	%%xmm0, %%xmm3\n\t"	"pand	%%xmm2, %%xmm1\n\t"
		"movdqa	%5, %%xmm0\n\t"		"pmullw	%8, %%xmm1\n\t"
		"pand	%%xmm3, %%xmm0\n\t"	"psrlw	$1, %%xmm1\n\t"
		"por	%%xmm0, %%xmm1\n\t"
		"pshufd	$78, %%xmm1, %%xmm0\n\t"
		"por	%%xmm0, %%xmm1\n\t"
		"pshufd	$177, %%xmm1, %%xmm0\n\t"
		"movd	%%xmm1, %%eax\n\t"
		"movd	%%xmm0, %%edx"
	: "=A" (flipped)
	: "m" (PL), "m" (PH), "m" (OL), "m" (OH), "m" (mask1), "m" (mask2), "m" (expmask), "m" (minusfour), "m" (k1e52), "m" (mulk1), "m" (mulk2));
#endif
	return flipped;
}
#endif

/**
 * Compute (zero-) flipped discs when plassing.
 *
 * @param P player's disc pattern.
 * @param O opponent's disc pattern.
 * @return flipped disc pattern.
 */
static UINT64 flip_pass(unsigned int PL, unsigned int PH, unsigned int OL, unsigned int OH)
{
	(void) PL; // useless code to shut-up compiler warning
	(void) PH;
	(void) OL;
	(void) OH;
	return 0;
}


/** Array of functions to compute flipped discs */
UINT64 (*flip[])(unsigned int, unsigned int, unsigned int, unsigned int) = {
#ifdef hasSSE2
	flip_sse_A1, flip_sse_B1, flip_sse_C1, flip_sse_D1, flip_sse_E1, flip_sse_F1, flip_sse_G1, flip_sse_H1,
	flip_sse_A2, flip_sse_B2, flip_sse_C2, flip_sse_D2, flip_sse_E2, flip_sse_F2, flip_sse_G2, flip_sse_H2,
	flip_sse_A3, flip_sse_B3, flip_sse_C3, flip_sse_D3, flip_sse_E3, flip_sse_F3, flip_sse_G3, flip_sse_H3,
	flip_sse_A4, flip_sse_B4, flip_sse_C4, flip_sse_D4, flip_sse_E4, flip_sse_F4, flip_sse_G4, flip_sse_H4,
	flip_sse_A5, flip_sse_B5, flip_sse_C5, flip_sse_D5, flip_sse_E5, flip_sse_F5, flip_sse_G5, flip_sse_H5,
	flip_sse_A6, flip_sse_B6, flip_sse_C6, flip_sse_D6, flip_sse_E6, flip_sse_F6, flip_sse_G6, flip_sse_H6,
	flip_sse_A7, flip_sse_B7, flip_sse_C7, flip_sse_D7, flip_sse_E7, flip_sse_F7, flip_sse_G7, flip_sse_H7,
	flip_sse_A8, flip_sse_B8, flip_sse_C8, flip_sse_D8, flip_sse_E8, flip_sse_F8, flip_sse_G8, flip_sse_H8,
#else
	flip_A1, flip_B1, flip_C1, flip_D1, flip_E1, flip_F1, flip_G1, flip_H1,
	flip_A2, flip_B2, flip_C2, flip_D2, flip_E2, flip_F2, flip_G2, flip_H2,
	flip_A3, flip_B3, flip_C3, flip_D3, flip_E3, flip_F3, flip_G3, flip_H3,
	flip_A4, flip_B4, flip_C4, flip_D4, flip_E4, flip_F4, flip_G4, flip_H4,
	flip_A5, flip_B5, flip_C5, flip_D5, flip_E5, flip_F5, flip_G5, flip_H5,
	flip_A6, flip_B6, flip_C6, flip_D6, flip_E6, flip_F6, flip_G6, flip_H6,
	flip_A7, flip_B7, flip_C7, flip_D7, flip_E7, flip_F7, flip_G7, flip_H7,
	flip_A8, flip_B8, flip_C8, flip_D8, flip_E8, flip_F8, flip_G8, flip_H8,
#endif
	flip_pass, flip_pass
};

#ifdef __TURBOC__	// entry from Delphi code
UINT64 flip32(unsigned int pos, unsigned int bb[]) {
	return (*flip[pos])(bb[0], bb[1], bb[2], bb[3]);
}
#endif

#if !defined(hasSSE2) && (defined(USE_GAS_MMX) || defined(USE_MSVC_X86))

static UINT64 (*flip_sse[])(unsigned int, unsigned int, unsigned int, unsigned int) = {
	flip_sse_A1, flip_sse_B1, flip_sse_C1, flip_sse_D1, flip_sse_E1, flip_sse_F1, flip_sse_G1, flip_sse_H1,
	flip_sse_A2, flip_sse_B2, flip_sse_C2, flip_sse_D2, flip_sse_E2, flip_sse_F2, flip_sse_G2, flip_sse_H2,
	flip_sse_A3, flip_sse_B3, flip_sse_C3, flip_sse_D3, flip_sse_E3, flip_sse_F3, flip_sse_G3, flip_sse_H3,
	flip_sse_A4, flip_sse_B4, flip_sse_C4, flip_sse_D4, flip_sse_E4, flip_sse_F4, flip_sse_G4, flip_sse_H4,
	flip_sse_A5, flip_sse_B5, flip_sse_C5, flip_sse_D5, flip_sse_E5, flip_sse_F5, flip_sse_G5, flip_sse_H5,
	flip_sse_A6, flip_sse_B6, flip_sse_C6, flip_sse_D6, flip_sse_E6, flip_sse_F6, flip_sse_G6, flip_sse_H6,
	flip_sse_A7, flip_sse_B7, flip_sse_C7, flip_sse_D7, flip_sse_E7, flip_sse_F7, flip_sse_G7, flip_sse_H7,
	flip_sse_A8, flip_sse_B8, flip_sse_C8, flip_sse_D8, flip_sse_E8, flip_sse_F8, flip_sse_G8, flip_sse_H8
};

void init_flip_sse(void) {
	memcpy(&flip[0], flip_sse, sizeof(flip_sse));
}
#endif

#ifdef USE_GAS_MMX
#undef	_
#endif
